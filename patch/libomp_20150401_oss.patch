diff --git a/CMakeLists.txt b/CMakeLists.txt
index fe50ed4..6eb3b90 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -340,6 +340,10 @@ if(${MAC})
 endif()
 set(inc_dir        "${LIBOMP_WORK}/src/include/${omp_version}")
 
+###############################
+# Flag to enable OpenMP suport
+option(TSAN_SUPPORT "Enable ThreadSanitizer support for data race detection in OpenMP programs" OFF)
+
 ############################
 # Setting final library name
 set(lib_item "libiomp")
@@ -359,6 +363,9 @@ set(lib_ext "${dll}")
 # libiomp5.dylib for Mac
 # libiomp5md.dll for Windows
 set(lib_file "${lib_item}${lib_ext}")
+if(TSAN_SUPPORT)
+set(lib_file_tsan "${lib_item}_tsan${lib_ext}")
+endif()
 
 ########################################
 # Setting export file names (full paths)
@@ -370,7 +377,7 @@ if(${WINDOWS})
         set(pdb_file "${lib_file}.pdb") # this is exported if it exists (libiomp5md.dll.pdb)
     endif()
 endif()
-set(export_lib_files  "${lib_file}" "${imp_file}" "${pdb_file}") 
+set(export_lib_files  "${lib_file}" "${lib_file_tsan}" "${imp_file}" "${pdb_file}") 
 set(export_inc_files  "iomp_lib.h")
 set(export_mod_files  "omp_lib.mod" "omp_lib_kinds.mod")
 set(export_cmn_files1 "omp.h" "omp_lib.h" "omp_lib.f" "omp_lib.f90")
@@ -382,7 +389,7 @@ add_prefix("${export_cmn_dir}/include/"        export_cmn_files1)
 add_prefix("${export_cmn_dir}/include_compat/" export_cmn_files2)
 set(export_cmn_files "${export_cmn_files1}" "${export_cmn_files2}")
 if("${export_lib_fat_dir}")
-    set(export_lib_fat_files "${lib_file}" "${imp_file}")
+    set(export_lib_fat_files "${lib_file}" "${lib_file_tsan}" "${imp_file}")
     add_prefix("${export_lib_fat_dir}/" export_lib_fat_files)
 endif()
 
@@ -586,6 +593,7 @@ simple_copy_recipe("omp_lib.f"         "${build_dir}"  "${export_cmn_dir}/includ
 simple_copy_recipe("omp_lib.f90"       "${build_dir}"  "${export_cmn_dir}/include")
 simple_copy_recipe("iomp.h"            "${build_dir}"  "${export_cmn_dir}/include_compat")
 simple_copy_recipe("${lib_file}"       "${build_dir}"  "${export_lib_dir}")
+simple_copy_recipe("${lib_file_tsan}"  "${build_dir}"  "${export_lib_dir}")
 simple_copy_recipe("${imp_file}"       "${build_dir}"  "${export_lib_dir}")
 simple_copy_recipe("${pdb_file}"       "${build_dir}"  "${export_lib_dir}")
 simple_copy_recipe("${dbg_file}"       "${build_dir}"  "${export_lib_dir}")
@@ -622,6 +630,9 @@ endif()
 
 # --- ${lib_file} rule ---
 add_library(iomp5 SHARED ${lib_src_files})
+if(TSAN_SUPPORT)
+add_library(iomp5_tsan SHARED ${lib_src_files})
+endif()
 set_target_properties(iomp5 PROPERTIES 
     PREFIX "" SUFFIX ""          # Take control 
     OUTPUT_NAME "${lib_file}"    # of output name
@@ -629,11 +640,27 @@ set_target_properties(iomp5 PROPERTIES
     LINKER_LANGUAGE C            # use C Compiler for linking step
     SKIP_BUILD_RPATH true        # have Mac linker -install_name just be "-install_name libiomp5.dylib"
 )
+if(TSAN_SUPPORT)
+set_target_properties(iomp5_tsan PROPERTIES 
+    PREFIX "" SUFFIX ""          # Take control 
+    OUTPUT_NAME "${lib_file_tsan}"    # of output name
+    COMPILE_FLAGS "-D DYNAMIC_ANNOTATIONS_ENABLED=1"
+    LINK_FLAGS  "${LD_FLAGS} -fsanitize=thread"     
+    LINKER_LANGUAGE C            # use C Compiler for linking step
+    SKIP_BUILD_RPATH true        # have Mac linker -install_name just be "-install_name libiomp5.dylib"
+)
+endif()
 # Target lib (export files) depend on the library (iomp5) being built
 add_dependencies(lib iomp5)
+if(TSAN_SUPPORT)
+add_dependencies(lib iomp5_tsan)
+endif()
 
 # Linking command will include libraries in LD_LIB_FLAGS
 target_link_libraries(iomp5 ${LD_LIB_FLAGS} ${CMAKE_DL_LIBS})
+if(TSAN_SUPPORT)
+target_link_libraries(iomp5_tsan ${LD_LIB_FLAGS} ${CMAKE_DL_LIBS})
+endif()
 
 # Create *.inc and omp.h before compiling any sources
 add_dependencies(iomp5 needed-headers)
@@ -737,6 +764,14 @@ if(${WINDOWS})
 endif()
 
 ######################################################
+# Install rules
+install (FILES ${build_dir}/${lib_file} DESTINATION lib)
+if(TSAN_SUPPORT)
+install (FILES ${build_dir}/${lib_file_tsan} DESTINATION lib)
+endif()
+install (FILES ${build_dir}/iomp.h ${build_dir}/iomp_lib.h ${build_dir}/omp.h ${build_dir}/omp_lib.h DESTINATION include)
+
+######################################################
 # kmp_i18n_id.inc and kmp_i18n_default.inc
 set(perlcmd "${PERL_EXECUTABLE}" "${tools_dir}/message-converter.pl" "${oa_opts}" "--prefix=kmp_i18n" "--enum=kmp_i18n_id.inc" "${src_dir}/i18n/en_US.txt")
 add_custom_command(
@@ -841,6 +876,7 @@ endif()
 say("Build Type           : ${CMAKE_BUILD_TYPE}")
 say("OpenMP Version       : ${omp_version}")
 say("Lib Type             : ${lib_type}")
+say("Tsan Support         : ${TSAN_SUPPORT}")
 say("Fortran Modules      : ${create_fortran_modules}")
 # will say development if all zeros
 if("${build_number}" STREQUAL "00000000")
diff --git a/Makefile b/Makefile
index b90b7d9..e7ed401 100644
--- a/Makefile
+++ b/Makefile
@@ -29,6 +29,8 @@
 # </copyright>
 
 omp_root?=.
+tsan?=enabled
+
 include $(omp_root)/tools/common.inc
 .PHONY: default all omp
 
@@ -37,12 +39,12 @@ default: omp
 all: omp stubs
 
 omp: info mkdir
-	@echo $(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) lib inc common -- -j$(jobs)
-	$(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) lib inc common -- -j$(jobs)
+	@echo $(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) --tsan=$(tsan) lib inc common
+	$(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) --tsan=$(tsan) lib inc common
 
 stubs: mkdir
-	@echo $(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) --stubs lib inc common -- -j$(jobs)
-	$(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) --stubs lib inc common -- -j$(jobs)
+	@echo $(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) --tsan=$(tsan) --stubs lib inc common 
+	$(omp_root)/tools/build.pl $(build_args) --arch=$(arch) --mode=$(mode) --tsan=$(tsan) --stubs lib inc common
 
 .PHONY: clean info
 
diff --git a/src/dynamic_annotations.h b/src/dynamic_annotations.h
index e69de29..e595d74 100644
--- a/src/dynamic_annotations.h
+++ b/src/dynamic_annotations.h
@@ -0,0 +1,661 @@
+/* Copyright (c) 2011, Google Inc.
+* All rights reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+* * Redistributions of source code must retain the above copyright
+* notice, this list of conditions and the following disclaimer.
+* * Neither the name of Google Inc. nor the names of its
+* contributors may be used to endorse or promote products derived from
+* this software without specific prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+* "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+* LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+* A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+* OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+* SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+* LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+* DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+* THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+* (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+/* This file defines dynamic annotations for use with dynamic analysis
+tool such as valgrind, PIN, etc.
+
+Dynamic annotation is a source code annotation that affects
+the generated code (that is, the annotation is not a comment).
+Each such annotation is attached to a particular
+instruction and/or to a particular object (address) in the program.
+
+The annotations that should be used by users are macros in all upper-case
+(e.g., ANNOTATE_NEW_MEMORY).
+
+Actual implementation of these macros may differ depending on the
+dynamic analysis tool being used.
+
+See http://code.google.com/p/data-race-test/ for more information.
+
+This file supports the following dynamic analysis tools:
+- None (DYNAMIC_ANNOTATIONS_ENABLED is not defined or zero).
+Macros are defined empty.
+- ThreadSanitizer, Helgrind, DRD (DYNAMIC_ANNOTATIONS_ENABLED is 1).
+Macros are defined as calls to non-inlinable empty functions
+that are intercepted by Valgrind. */
+
+#ifndef __DYNAMIC_ANNOTATIONS_H__
+#define __DYNAMIC_ANNOTATIONS_H__
+
+#ifndef DYNAMIC_ANNOTATIONS_PREFIX
+# define DYNAMIC_ANNOTATIONS_PREFIX
+#endif
+
+// #ifndef DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND
+// # define DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND 1
+// #endif
+
+#ifdef DYNAMIC_ANNOTATIONS_WANT_ATTRIBUTE_WEAK
+# ifdef __GNUC__
+# define DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK __attribute__((weak))
+# else
+/* TODO(glider): for Windows support we may want to change this macro in order
+to prepend __declspec(selectany) to the annotations' declarations. */
+# error weak annotations are not supported for your compiler
+# endif
+#else
+# define DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK
+#endif
+
+/* The following preprocessor magic prepends the value of
+DYNAMIC_ANNOTATIONS_PREFIX to annotation function names. */
+#define DYNAMIC_ANNOTATIONS_GLUE0(A, B) A##B
+#define DYNAMIC_ANNOTATIONS_GLUE(A, B) DYNAMIC_ANNOTATIONS_GLUE0(A, B)
+#define DYNAMIC_ANNOTATIONS_NAME(name) \
+DYNAMIC_ANNOTATIONS_GLUE(DYNAMIC_ANNOTATIONS_PREFIX, name)
+
+//#undef DYNAMIC_ANNOTATIONS_ENABLED
+//# define DYNAMIC_ANNOTATIONS_ENABLED 0
+
+#ifndef DYNAMIC_ANNOTATIONS_ENABLED
+# define DYNAMIC_ANNOTATIONS_ENABLED 0
+#endif
+
+#if DYNAMIC_ANNOTATIONS_ENABLED != 0
+
+  /* -------------------------------------------------------------
+Annotations useful when implementing condition variables such as CondVar,
+using conditional critical sections (Await/LockWhen) and when constructing
+user-defined synchronization mechanisms.
+
+The annotations ANNOTATE_HAPPENS_BEFORE() and ANNOTATE_HAPPENS_AFTER() can
+be used to define happens-before arcs in user-defined synchronization
+mechanisms: the race detector will infer an arc from the former to the
+latter when they share the same argument pointer.
+
+Example 1 (reference counting):
+
+void Unref() {
+ANNOTATE_HAPPENS_BEFORE(&refcount_);
+if (AtomicDecrementByOne(&refcount_) == 0) {
+ANNOTATE_HAPPENS_AFTER(&refcount_);
+delete this;
+}
+}
+
+Example 2 (message queue):
+
+void MyQueue::Put(Type *e) {
+MutexLock lock(&mu_);
+ANNOTATE_HAPPENS_BEFORE(e);
+PutElementIntoMyQueue(e);
+}
+
+Type *MyQueue::Get() {
+MutexLock lock(&mu_);
+Type *e = GetElementFromMyQueue();
+ANNOTATE_HAPPENS_AFTER(e);
+return e;
+}
+
+Note: when possible, please use the existing reference counting and message
+queue implementations instead of inventing new ones. */
+
+  /* Report that wait on the condition variable at address "cv" has succeeded
+and the lock at address "lock" is held. */
+#define ANNOTATE_CONDVAR_LOCK_WAIT(cv, lock) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarWait)(__FILE__, __LINE__, cv, lock)
+
+  /* Report that wait on the condition variable at "cv" has succeeded. Variant
+w/o lock. */
+#define ANNOTATE_CONDVAR_WAIT(cv) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarWait)(__FILE__, __LINE__, cv, NULL)
+
+  /* Report that we are about to signal on the condition variable at address
+"cv". */
+#define ANNOTATE_CONDVAR_SIGNAL(cv) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignal)(__FILE__, __LINE__, cv)
+
+  /* Report that we are about to signal_all on the condition variable at address
+"cv". */
+#define ANNOTATE_CONDVAR_SIGNAL_ALL(cv) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignalAll)(__FILE__, __LINE__, cv)
+
+  /* Annotations for user-defined synchronization mechanisms. */
+  #define ANNOTATE_HAPPENS_BEFORE(obj) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensBefore)(__FILE__, __LINE__, obj)
+#define ANNOTATE_HAPPENS_AFTER(obj) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensAfter)(__FILE__, __LINE__, obj)
+
+  /* DEPRECATED. Don't use it. */
+  #define ANNOTATE_PUBLISH_MEMORY_RANGE(pointer, size) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePublishMemoryRange)(__FILE__, __LINE__, \
+pointer, size)
+
+  /* DEPRECATED. Don't use it. */
+  #define ANNOTATE_UNPUBLISH_MEMORY_RANGE(pointer, size) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateUnpublishMemoryRange)(__FILE__, __LINE__, \
+pointer, size)
+
+  /* DEPRECATED. Don't use it. */
+  #define ANNOTATE_SWAP_MEMORY_RANGE(pointer, size) \
+do { \
+ANNOTATE_UNPUBLISH_MEMORY_RANGE(pointer, size); \
+ANNOTATE_PUBLISH_MEMORY_RANGE(pointer, size); \
+} while (0)
+
+  /* Instruct the tool to create a happens-before arc between mu->Unlock() and
+mu->Lock(). This annotation may slow down the race detector and hide real
+races. Normally it is used only when it would be difficult to annotate each
+of the mutex's critical sections individually using the annotations above.
+This annotation makes sense only for hybrid race detectors. For pure
+happens-before detectors this is a no-op. For more details see
+http://code.google.com/p/data-race-test/wiki/PureHappensBeforeVsHybrid . */
+#define ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX(mu) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsUsedAsCondVar)(__FILE__, __LINE__, \
+mu)
+
+  /* Opposite to ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX.
+Instruct the tool to NOT create h-b arcs between Unlock and Lock, even in
+pure happens-before mode. For a hybrid mode this is a no-op. */
+#define ANNOTATE_NOT_HAPPENS_BEFORE_MUTEX(mu) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsNotPHB)(__FILE__, __LINE__, mu)
+
+  /* Deprecated. Use ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX. */
+  #define ANNOTATE_MUTEX_IS_USED_AS_CONDVAR(mu) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsUsedAsCondVar)(__FILE__, __LINE__, \
+mu)
+
+  /* -------------------------------------------------------------
+Annotations useful when defining memory allocators, or when memory that
+was protected in one way starts to be protected in another. */
+
+  /* Report that a new memory at "address" of size "size" has been allocated.
+This might be used when the memory has been retrieved from a free list and
+is about to be reused, or when a the locking discipline for a variable
+changes. */
+#define ANNOTATE_NEW_MEMORY(address, size) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateNewMemory)(__FILE__, __LINE__, address, \
+size)
+
+  /* -------------------------------------------------------------
+Annotations useful when defining FIFO queues that transfer data between
+threads. */
+
+  /* Report that the producer-consumer queue (such as ProducerConsumerQueue) at
+address "pcq" has been created. The ANNOTATE_PCQ_* annotations
+should be used only for FIFO queues. For non-FIFO queues use
+ANNOTATE_HAPPENS_BEFORE (for put) and ANNOTATE_HAPPENS_AFTER (for get). */
+#define ANNOTATE_PCQ_CREATE(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQCreate)(__FILE__, __LINE__, pcq)
+
+  /* Report that the queue at address "pcq" is about to be destroyed. */
+  #define ANNOTATE_PCQ_DESTROY(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQDestroy)(__FILE__, __LINE__, pcq)
+
+  /* Report that we are about to put an element into a FIFO queue at address
+"pcq". */
+#define ANNOTATE_PCQ_PUT(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQPut)(__FILE__, __LINE__, pcq)
+
+  /* Report that we've just got an element from a FIFO queue at address
+"pcq". */
+#define ANNOTATE_PCQ_GET(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQGet)(__FILE__, __LINE__, pcq)
+
+  /* -------------------------------------------------------------
+Annotations that suppress errors. It is usually better to express the
+program's synchronization using the other annotations, but these can
+be used when all else fails. */
+
+  /* Report that we may have a benign race at "pointer", with size
+"sizeof(*(pointer))". "pointer" must be a non-void* pointer. Insert at the
+point where "pointer" has been allocated, preferably close to the point
+where the race happens. See also ANNOTATE_BENIGN_RACE_STATIC. */
+#define ANNOTATE_BENIGN_RACE(pointer, description) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRaceSized)(__FILE__, __LINE__, \
+pointer, sizeof(*(pointer)), description)
+
+  /* Same as ANNOTATE_BENIGN_RACE(address, description), but applies to
+the memory range [address, address+size). */
+#define ANNOTATE_BENIGN_RACE_SIZED(address, size, description) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRaceSized)(__FILE__, __LINE__, \
+address, size, description)
+
+  /* Request the analysis tool to ignore all reads in the current thread
+until ANNOTATE_IGNORE_READS_END is called.
+Useful to ignore intentional racey reads, while still checking
+other reads and all writes.
+See also ANNOTATE_UNPROTECTED_READ. */
+#define ANNOTATE_IGNORE_READS_BEGIN() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsBegin)(__FILE__, __LINE__)
+
+  /* Stop ignoring reads. */
+  #define ANNOTATE_IGNORE_READS_END() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsEnd)(__FILE__, __LINE__)
+
+  /* Similar to ANNOTATE_IGNORE_READS_BEGIN, but ignore writes. */
+  #define ANNOTATE_IGNORE_WRITES_BEGIN() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesBegin)(__FILE__, __LINE__)
+
+  /* Stop ignoring writes. */
+  #define ANNOTATE_IGNORE_WRITES_END() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesEnd)(__FILE__, __LINE__)
+
+  /* Start ignoring all memory accesses (reads and writes). */
+  #define ANNOTATE_IGNORE_READS_AND_WRITES_BEGIN() \
+do {\
+ANNOTATE_IGNORE_READS_BEGIN();\
+ANNOTATE_IGNORE_WRITES_BEGIN();\
+}while(0)\
+
+  /* Stop ignoring all memory accesses. */
+  #define ANNOTATE_IGNORE_READS_AND_WRITES_END() \
+do {\
+ANNOTATE_IGNORE_WRITES_END();\
+ANNOTATE_IGNORE_READS_END();\
+}while(0)\
+
+  /* Similar to ANNOTATE_IGNORE_READS_BEGIN, but ignore synchronization events:
+RWLOCK* and CONDVAR*. */
+#define ANNOTATE_IGNORE_SYNC_BEGIN() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncBegin)(__FILE__, __LINE__)
+
+  /* Stop ignoring sync events. */
+  #define ANNOTATE_IGNORE_SYNC_END() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncEnd)(__FILE__, __LINE__)
+
+
+  /* Enable (enable!=0) or disable (enable==0) race detection for all threads.
+This annotation could be useful if you want to skip expensive race analysis
+during some period of program execution, e.g. during initialization. */
+#define ANNOTATE_ENABLE_RACE_DETECTION(enable) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateEnableRaceDetection)(__FILE__, __LINE__, \
+enable)
+
+  /* -------------------------------------------------------------
+Annotations useful for debugging. */
+
+  /* Request to trace every access to "address". */
+  #define ANNOTATE_TRACE_MEMORY(address) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateTraceMemory)(__FILE__, __LINE__, address)
+
+  /* Report the current thread name to a race detector. */
+  #define ANNOTATE_THREAD_NAME(name) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateThreadName)(__FILE__, __LINE__, name)
+
+  /* -------------------------------------------------------------
+Annotations useful when implementing locks. They are not
+normally needed by modules that merely use locks.
+The "lock" argument is a pointer to the lock object. */
+
+  /* Report that a lock has been created at address "lock". */
+  #define ANNOTATE_RWLOCK_CREATE(lock) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockCreate)(__FILE__, __LINE__, lock)
+
+  /* Report that the lock at address "lock" is about to be destroyed. */
+  #define ANNOTATE_RWLOCK_DESTROY(lock) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockDestroy)(__FILE__, __LINE__, lock)
+
+  /* Report that the lock at address "lock" has been acquired.
+is_w=1 for writer lock, is_w=0 for reader lock. */
+#define ANNOTATE_RWLOCK_ACQUIRED(lock, is_w) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockAcquired)(__FILE__, __LINE__, lock, \
+is_w)
+
+  /* Report that the lock at address "lock" is about to be released. */
+  #define ANNOTATE_RWLOCK_RELEASED(lock, is_w) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockReleased)(__FILE__, __LINE__, lock, \
+is_w)
+
+  /* -------------------------------------------------------------
+Annotations useful when implementing barriers. They are not
+normally needed by modules that merely use barriers.
+The "barrier" argument is a pointer to the barrier object. */
+
+  /* Report that the "barrier" has been initialized with initial "count".
+If 'reinitialization_allowed' is true, initialization is allowed to happen
+multiple times w/o calling barrier_destroy() */
+#define ANNOTATE_BARRIER_INIT(barrier, count, reinitialization_allowed) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierInit)(__FILE__, __LINE__, barrier, \
+count, reinitialization_allowed)
+
+  /* Report that we are about to enter barrier_wait("barrier"). */
+  #define ANNOTATE_BARRIER_WAIT_BEFORE(barrier) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitBefore)(__FILE__, __LINE__, \
+barrier)
+
+  /* Report that we just exited barrier_wait("barrier"). */
+  #define ANNOTATE_BARRIER_WAIT_AFTER(barrier) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitAfter)(__FILE__, __LINE__, \
+barrier)
+
+  /* Report that the "barrier" has been destroyed. */
+  #define ANNOTATE_BARRIER_DESTROY(barrier) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierDestroy)(__FILE__, __LINE__, \
+barrier)
+
+  /* -------------------------------------------------------------
+Annotations useful for testing race detectors. */
+
+  /* Report that we expect a race on the variable at "address".
+Use only in unit tests for a race detector. */
+#define ANNOTATE_EXPECT_RACE(address, description) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateExpectRace)(__FILE__, __LINE__, address, \
+description)
+
+#define ANNOTATE_FLUSH_EXPECTED_RACES() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushExpectedRaces)(__FILE__, __LINE__)
+
+  /* A no-op. Insert where you like to test the interceptors. */
+  #define ANNOTATE_NO_OP(arg) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateNoOp)(__FILE__, __LINE__, arg)
+
+  /* Force the race detector to flush its state. The actual effect depends on
+* the implementation of the detector. */
+#define ANNOTATE_FLUSH_STATE() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushState)(__FILE__, __LINE__)
+
+
+#else /* DYNAMIC_ANNOTATIONS_ENABLED == 0 */
+
+#define ANNOTATE_RWLOCK_CREATE(lock) /* empty */
+#define ANNOTATE_RWLOCK_DESTROY(lock) /* empty */
+#define ANNOTATE_RWLOCK_ACQUIRED(lock, is_w) /* empty */
+#define ANNOTATE_RWLOCK_RELEASED(lock, is_w) /* empty */
+#define ANNOTATE_BARRIER_INIT(barrier, count, reinitialization_allowed) /* */
+#define ANNOTATE_BARRIER_WAIT_BEFORE(barrier) /* empty */
+#define ANNOTATE_BARRIER_WAIT_AFTER(barrier) /* empty */
+#define ANNOTATE_BARRIER_DESTROY(barrier) /* empty */
+#define ANNOTATE_CONDVAR_LOCK_WAIT(cv, lock) /* empty */
+#define ANNOTATE_CONDVAR_WAIT(cv) /* empty */
+#define ANNOTATE_CONDVAR_SIGNAL(cv) /* empty */
+#define ANNOTATE_CONDVAR_SIGNAL_ALL(cv) /* empty */
+#define ANNOTATE_HAPPENS_BEFORE(obj) /* empty */
+#define ANNOTATE_HAPPENS_AFTER(obj) /* empty */
+#define ANNOTATE_PUBLISH_MEMORY_RANGE(address, size) /* empty */
+#define ANNOTATE_UNPUBLISH_MEMORY_RANGE(address, size) /* empty */
+#define ANNOTATE_SWAP_MEMORY_RANGE(address, size) /* empty */
+#define ANNOTATE_PCQ_CREATE(pcq) /* empty */
+#define ANNOTATE_PCQ_DESTROY(pcq) /* empty */
+#define ANNOTATE_PCQ_PUT(pcq) /* empty */
+#define ANNOTATE_PCQ_GET(pcq) /* empty */
+#define ANNOTATE_NEW_MEMORY(address, size) /* empty */
+#define ANNOTATE_EXPECT_RACE(address, description) /* empty */
+#define ANNOTATE_FLUSH_EXPECTED_RACES(address, description) /* empty */
+#define ANNOTATE_BENIGN_RACE(address, description) /* empty */
+#define ANNOTATE_BENIGN_RACE_SIZED(address, size, description) /* empty */
+#define ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX(mu) /* empty */
+#define ANNOTATE_MUTEX_IS_USED_AS_CONDVAR(mu) /* empty */
+#define ANNOTATE_TRACE_MEMORY(arg) /* empty */
+#define ANNOTATE_THREAD_NAME(name) /* empty */
+#define ANNOTATE_IGNORE_READS_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_READS_END() /* empty */
+#define ANNOTATE_IGNORE_WRITES_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_WRITES_END() /* empty */
+#define ANNOTATE_IGNORE_READS_AND_WRITES_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_READS_AND_WRITES_END() /* empty */
+#define ANNOTATE_IGNORE_SYNC_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_SYNC_END() /* empty */
+#define ANNOTATE_ENABLE_RACE_DETECTION(enable) /* empty */
+#define ANNOTATE_NO_OP(arg) /* empty */
+#define ANNOTATE_FLUSH_STATE() /* empty */
+
+#endif /* DYNAMIC_ANNOTATIONS_ENABLED */
+
+//#undef ANNOTATE_HAPPENS_BEFORE
+//#undef ANNOTATE_HAPPENS_AFTER
+//#define ANNOTATE_HAPPENS_BEFORE(obj) /* empty */
+//#define ANNOTATE_HAPPENS_AFTER(obj) /* empty */
+
+/* specify the locks to be instrumented */
+#define ANNOTATE_QUEUING
+ #define ANNOTATE_TICKET
+#define ANNOTATE_FUTEX
+ #define ANNOTATE_TAS
+#define ANNOTATE_DRDPA
+
+#ifdef ANNOTATE_QUEUING
+#define ANNOTATE_QUEUING_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_QUEUING_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_QUEUING_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_QUEUING_CREATE(lck) (void)0
+#define ANNOTATE_QUEUING_RELEASED(lck) (void)0
+#define ANNOTATE_QUEUING_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_TICKET
+#define ANNOTATE_TICKET_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_TICKET_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_TICKET_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_TICKET_CREATE(lck) (void)0
+#define ANNOTATE_TICKET_RELEASED(lck) (void)0
+#define ANNOTATE_TICKET_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_FUTEX
+#define ANNOTATE_FUTEX_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_FUTEX_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_FUTEX_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_FUTEX_CREATE(lck) (void)0
+#define ANNOTATE_FUTEX_RELEASED(lck) (void)0
+#define ANNOTATE_FUTEX_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_TAS
+#define ANNOTATE_TAS_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_TAS_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_TAS_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_TAS_CREATE(lck) (void)0
+#define ANNOTATE_TAS_RELEASED(lck) (void)0
+#define ANNOTATE_TAS_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_DRDPA
+#define ANNOTATE_DRDPA_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_DRDPA_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_DRDPA_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_DRDPA_CREATE(lck) (void)0
+#define ANNOTATE_DRDPA_RELEASED(lck) (void)0
+#define ANNOTATE_DRDPA_ACQUIRED(lck) (void)0
+#endif
+
+
+/* Use the macros above rather than using these functions directly. */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockCreate)(
+    const char *file, int line,
+    const volatile void *lock) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockDestroy)(
+    const char *file, int line,
+    const volatile void *lock) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockAcquired)(
+    const char *file, int line,
+    const volatile void *lock, long is_w) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockReleased)(
+    const char *file, int line,
+    const volatile void *lock, long is_w) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierInit)(
+    const char *file, int line, const volatile void *barrier, long count,
+    long reinitialization_allowed) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitBefore)(
+    const char *file, int line,
+    const volatile void *barrier) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitAfter)(
+    const char *file, int line,
+    const volatile void *barrier) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierDestroy)(
+    const char *file, int line,
+    const volatile void *barrier) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarWait)(
+    const char *file, int line, const volatile void *cv,
+    const volatile void *lock) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignal)(
+    const char *file, int line,
+    const volatile void *cv) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignalAll)(
+    const char *file, int line,
+    const volatile void *cv) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensBefore)(
+    const char *file, int line,
+    const volatile void *obj) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensAfter)(
+    const char *file, int line,
+    const volatile void *obj) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePublishMemoryRange)(
+    const char *file, int line,
+    const volatile void *address, long size) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateUnpublishMemoryRange)(
+    const char *file, int line,
+    const volatile void *address, long size) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQCreate)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQDestroy)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQPut)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQGet)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateNewMemory)(
+    const char *file, int line,
+    const volatile void *mem, long size) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateExpectRace)(
+    const char *file, int line, const volatile void *mem,
+    const char *description) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushExpectedRaces)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRace)(
+    const char *file, int line, const volatile void *mem,
+    const char *description) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRaceSized)(
+    const char *file, int line, const volatile void *mem, long size,
+    const char *description) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsUsedAsCondVar)(
+    const char *file, int line,
+    const volatile void *mu) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsNotPHB)(
+    const char *file, int line,
+    const volatile void *mu) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateTraceMemory)(
+    const char *file, int line,
+    const volatile void *arg) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateThreadName)(
+    const char *file, int line,
+    const char *name) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsBegin)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsEnd)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesBegin)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesEnd)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncBegin)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncEnd)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateEnableRaceDetection)(
+    const char *file, int line, int enable) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateNoOp)(
+    const char *file, int line,
+    const volatile void *arg) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushState)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+
+#if DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND == 1
+/* Return non-zero value if running under valgrind.
+
+If "valgrind.h" is included into dynamic_annotations.c,
+the regular valgrind mechanism will be used.
+See http://valgrind.org/docs/manual/manual-core-adv.html about
+RUNNING_ON_VALGRIND and other valgrind "client requests".
+The file "valgrind.h" may be obtained by doing
+svn co svn://svn.valgrind.org/valgrind/trunk/include
+
+If for some reason you can't use "valgrind.h" or want to fake valgrind,
+there are two ways to make this function return non-zero:
+- Use environment variable: export RUNNING_ON_VALGRIND=1
+- Make your tool intercept the function RunningOnValgrind() and
+change its return value.
+*/
+int RunningOnValgrind(void) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+#endif /* DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND == 1 */
+
+#ifdef __cplusplus
+}
+#endif
+
+#if DYNAMIC_ANNOTATIONS_ENABLED != 0 && defined(__cplusplus)
+
+  /* ANNOTATE_UNPROTECTED_READ is the preferred way to annotate racey reads.
+
+Instead of doing
+ANNOTATE_IGNORE_READS_BEGIN();
+... = x;
+ANNOTATE_IGNORE_READS_END();
+one can use
+... = ANNOTATE_UNPROTECTED_READ(x); */
+  template <class T>
+  inline T ANNOTATE_UNPROTECTED_READ(const volatile T &x) {
+    ANNOTATE_IGNORE_READS_BEGIN();
+    T res = x;
+    ANNOTATE_IGNORE_READS_END();
+    return res;
+  }
+  /* Apply ANNOTATE_BENIGN_RACE_SIZED to a static variable. */
+  #define ANNOTATE_BENIGN_RACE_STATIC(static_var, description) \
+namespace { \
+class static_var ## _annotator { \
+public: \
+static_var ## _annotator() { \
+ANNOTATE_BENIGN_RACE_SIZED(&static_var, \
+sizeof(static_var), \
+# static_var ": " description); \
+} \
+}; \
+static static_var ## _annotator the ## static_var ## _annotator;\
+}
+#else /* DYNAMIC_ANNOTATIONS_ENABLED == 0 */
+
+#define ANNOTATE_UNPROTECTED_READ(x) (x)
+#define ANNOTATE_BENIGN_RACE_STATIC(static_var, description) /* empty */
+
+#endif /* DYNAMIC_ANNOTATIONS_ENABLED */
+
+#endif /* __DYNAMIC_ANNOTATIONS_H__ */
diff --git a/src/kmp_barrier.cpp b/src/kmp_barrier.cpp
index 90efbb9..f44f84b 100644
--- a/src/kmp_barrier.cpp
+++ b/src/kmp_barrier.cpp
@@ -55,6 +55,8 @@
 #define ngo_sync()               ((void)0)
 #endif /* KMP_MIC && USE_NGO_STORES */
 
+#include "dynamic_annotations.h"
+
 void __kmp_print_structure(void); // Forward declaration
 
 // ---------------------------- Barrier Algorithms ----------------------------
@@ -89,6 +91,7 @@ __kmp_linear_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr, int gtid
         // Mark arrival to master thread
         /* After performing this write, a worker thread may not assume that the team is valid
            any more - it could be deallocated by the master thread at any time. */
+	ANNOTATE_HAPPENS_BEFORE(this_thr);
         kmp_flag_64 flag(&thr_bar->b_arrived, other_threads[0]);
         flag.release();
     } else {
@@ -114,6 +117,7 @@ __kmp_linear_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr, int gtid
             kmp_flag_64 flag(&other_threads[i]->th.th_bar[bt].bb.b_arrived, new_state);
             flag.wait(this_thr, FALSE
                       USE_ITT_BUILD_ARG(itt_sync_obj) );
+	    ANNOTATE_HAPPENS_AFTER(other_threads[ i ]);
 #if USE_ITT_BUILD && USE_ITT_NOTIFY
             // Barrier imbalance - write min of the thread time and the other thread time to the thread.
             if (__kmp_forkjoin_frames_mode == 2) {
@@ -186,6 +190,7 @@ __kmp_linear_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, int gti
                               &other_threads[i]->th.th_bar[bt].bb.b_go,
                               other_threads[i]->th.th_bar[bt].bb.b_go,
                               other_threads[i]->th.th_bar[bt].bb.b_go + KMP_BARRIER_STATE_BUMP));
+		ANNOTATE_HAPPENS_BEFORE(other_threads[i]);
                 kmp_flag_64 flag(&other_threads[i]->th.th_bar[bt].bb.b_go, other_threads[i]);
                 flag.release();
             }
@@ -196,6 +201,8 @@ __kmp_linear_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, int gti
         kmp_flag_64 flag(&thr_bar->b_go, KMP_BARRIER_STATE_BUMP);
         flag.wait(this_thr, TRUE
                   USE_ITT_BUILD_ARG(itt_sync_obj) );
+        ANNOTATE_HAPPENS_AFTER(this_thr);
+
 #if USE_ITT_BUILD && USE_ITT_NOTIFY
         if ((__itt_sync_create_ptr && itt_sync_obj == NULL) || KMP_ITT_DEBUG) {
             // In a fork barrier; cannot get the object reliably (or ITTNOTIFY is disabled)
@@ -279,6 +286,7 @@ __kmp_tree_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr, int gtid,
             kmp_flag_64 flag(&child_bar->b_arrived, new_state);
             flag.wait(this_thr, FALSE
                       USE_ITT_BUILD_ARG(itt_sync_obj) );
+	        ANNOTATE_HAPPENS_AFTER(child_thr);
 #if USE_ITT_BUILD && USE_ITT_NOTIFY
             // Barrier imbalance - write min of the thread time and a child time to the thread.
             if (__kmp_forkjoin_frames_mode == 2) {
@@ -310,6 +318,7 @@ __kmp_tree_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr, int gtid,
         // Mark arrival to parent thread
         /* After performing this write, a worker thread may not assume that the team is valid
            any more - it could be deallocated by the master thread at any time.  */
+	    ANNOTATE_HAPPENS_BEFORE(this_thr);
         kmp_flag_64 flag(&thr_bar->b_arrived, other_threads[parent_tid]);
         flag.release();
     } else {
@@ -348,6 +357,7 @@ __kmp_tree_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, int gtid,
         kmp_flag_64 flag(&thr_bar->b_go, KMP_BARRIER_STATE_BUMP);
         flag.wait(this_thr, TRUE
                   USE_ITT_BUILD_ARG(itt_sync_obj) );
+	    ANNOTATE_HAPPENS_AFTER(this_thr);
 #if USE_ITT_BUILD && USE_ITT_NOTIFY
         if ((__itt_sync_create_ptr && itt_sync_obj == NULL) || KMP_ITT_DEBUG) {
             // In fork barrier where we could not get the object reliably (or ITTNOTIFY is disabled)
@@ -415,6 +425,7 @@ __kmp_tree_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, int gtid,
                           child_tid, &child_bar->b_go, child_bar->b_go,
                           child_bar->b_go + KMP_BARRIER_STATE_BUMP));
             // Release child from barrier
+	        ANNOTATE_HAPPENS_BEFORE(child_thr);
             kmp_flag_64 flag(&child_bar->b_go, child_thr);
             flag.release();
             child++;
@@ -475,6 +486,7 @@ __kmp_hyper_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr, int gtid,
             /* After performing this write (in the last iteration of the enclosing for loop),
                a worker thread may not assume that the team is valid any more - it could be
                deallocated by the master thread at any time.  */
+	        ANNOTATE_HAPPENS_BEFORE(this_thr);
             p_flag.set_waiter(other_threads[parent_tid]);
 	    p_flag.release();
             break;
@@ -502,6 +514,7 @@ __kmp_hyper_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr, int gtid,
             kmp_flag_64 c_flag(&child_bar->b_arrived, new_state);
             c_flag.wait(this_thr, FALSE
                         USE_ITT_BUILD_ARG(itt_sync_obj) );
+	        ANNOTATE_HAPPENS_AFTER(child_thr);
 #if USE_ITT_BUILD && USE_ITT_NOTIFY
             // Barrier imbalance - write min of the thread time and a child time to the thread.
             if (__kmp_forkjoin_frames_mode == 2) {
@@ -572,6 +585,8 @@ __kmp_hyper_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, int gtid
         kmp_flag_64 flag(&thr_bar->b_go, KMP_BARRIER_STATE_BUMP);
         flag.wait(this_thr, TRUE
                   USE_ITT_BUILD_ARG(itt_sync_obj) );
+	   ANNOTATE_HAPPENS_AFTER(this_thr);
+
 #if USE_ITT_BUILD && USE_ITT_NOTIFY
         if ((__itt_sync_create_ptr && itt_sync_obj == NULL) || KMP_ITT_DEBUG) {
             // In fork barrier where we could not get the object reliably
@@ -659,6 +674,7 @@ __kmp_hyper_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, int gtid
                               child_tid, &child_bar->b_go, child_bar->b_go,
                               child_bar->b_go + KMP_BARRIER_STATE_BUMP));
                 // Release child from barrier
+		        ANNOTATE_HAPPENS_BEFORE(child_thr);
                 kmp_flag_64 flag(&child_bar->b_go, child_thr);
                 flag.release();
             }
@@ -785,9 +801,17 @@ __kmp_hierarchical_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr,
                         KA_TRACE(100, ("__kmp_hierarchical_barrier_gather: T#%d(%d:%d) += T#%d(%d:%d)\n",
                                        gtid, team->t.t_id, tid, __kmp_gtid_from_tid(child_tid, team),
                                        team->t.t_id, child_tid));
+			            ANNOTATE_HAPPENS_AFTER(other_threads[child_tid]);
                         (*reduce)(this_thr->th.th_local.reduce_data, other_threads[child_tid]->th.th_local.reduce_data);
                     }
                 }
+#ifdef DYN
+		else{
+		  for (child_tid=tid+1; child_tid<=tid+thr_bar->leaf_kids; ++child_tid) {
+		    ANNOTATE_HAPPENS_AFTER(other_threads[child_tid]);
+		  }
+                }
+#endif
                 (void) KMP_TEST_THEN_AND64((volatile kmp_int64 *)&thr_bar->b_arrived, ~(thr_bar->leaf_state)); // clear leaf_state bits
             }
             // Next, wait for higher level children on each child's b_arrived flag
@@ -804,6 +828,7 @@ __kmp_hierarchical_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr,
                     kmp_flag_64 flag(&child_bar->b_arrived, new_state);
                     flag.wait(this_thr, FALSE
                               USE_ITT_BUILD_ARG(itt_sync_obj) );
+		            ANNOTATE_HAPPENS_AFTER(child_thr);
                     if (reduce) {
                         KA_TRACE(100, ("__kmp_hierarchical_barrier_gather: T#%d(%d:%d) += T#%d(%d:%d)\n",
                                        gtid, team->t.t_id, tid, __kmp_gtid_from_tid(child_tid, team),
@@ -827,6 +852,7 @@ __kmp_hierarchical_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr,
                     kmp_flag_64 flag(&child_bar->b_arrived, new_state);
                     flag.wait(this_thr, FALSE
                               USE_ITT_BUILD_ARG(itt_sync_obj) );
+		            ANNOTATE_HAPPENS_AFTER(child_thr);
                     if (reduce) {
                         KA_TRACE(100, ("__kmp_hierarchical_barrier_gather: T#%d(%d:%d) += T#%d(%d:%d)\n",
                                        gtid, team->t.t_id, tid, __kmp_gtid_from_tid(child_tid, team),
@@ -848,6 +874,7 @@ __kmp_hierarchical_barrier_gather(enum barrier_type bt, kmp_info_t *this_thr,
            the team is valid any more - it could be deallocated by the master thread at any time. */
         if (thr_bar->my_level || __kmp_dflt_blocktime != KMP_MAX_BLOCKTIME
             || !thr_bar->use_oncore_barrier) { // Parent is waiting on my b_arrived flag; release it
+	        ANNOTATE_HAPPENS_BEFORE(this_thr);
             kmp_flag_64 flag(&thr_bar->b_arrived, other_threads[thr_bar->parent_tid]);
             flag.release();
         }
@@ -893,6 +920,7 @@ __kmp_hierarchical_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, i
             kmp_flag_64 flag(&thr_bar->b_go, KMP_BARRIER_STATE_BUMP);
             flag.wait(this_thr, TRUE
                       USE_ITT_BUILD_ARG(itt_sync_obj) );
+	        ANNOTATE_HAPPENS_AFTER(this_thr);
             TCW_8(thr_bar->b_go, KMP_INIT_BARRIER_STATE); // Reset my b_go flag for next time
         }
         else { // Thread barrier data is initialized, this is a leaf, blocktime is infinite, not nested
@@ -1007,6 +1035,7 @@ __kmp_hierarchical_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, i
                                       team->t.t_id, child_tid, &child_bar->b_go, child_bar->b_go,
                                       child_bar->b_go + KMP_BARRIER_STATE_BUMP));
                         // Release child using child's b_go flag
+			            ANNOTATE_HAPPENS_BEFORE(child_thr);
                         kmp_flag_64 flag(&child_bar->b_go, child_thr);
                         flag.release();
                     }
@@ -1030,6 +1059,7 @@ __kmp_hierarchical_barrier_release(enum barrier_type bt, kmp_info_t *this_thr, i
                                   team->t.t_id, child_tid, &child_bar->b_go, child_bar->b_go,
                                   child_bar->b_go + KMP_BARRIER_STATE_BUMP));
                     // Release child using child's b_go flag
+		            ANNOTATE_HAPPENS_BEFORE(child_thr);
                     kmp_flag_64 flag(&child_bar->b_go, child_thr);
                     flag.release();
                 }
diff --git a/src/kmp_lock.cpp b/src/kmp_lock.cpp
index a7d5506..7e627f0 100644
--- a/src/kmp_lock.cpp
+++ b/src/kmp_lock.cpp
@@ -40,6 +40,8 @@
 #include "kmp_lock.h"
 #include "kmp_io.h"
 
+#include "dynamic_annotations.h"
+
 #if KMP_OS_LINUX && (KMP_ARCH_X86 || KMP_ARCH_X86_64 || KMP_ARCH_ARM || KMP_ARCH_AARCH64)
 # include <unistd.h>
 # include <sys/syscall.h>
@@ -152,6 +154,7 @@ void
 __kmp_acquire_tas_lock( kmp_tas_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_tas_lock_timed_template( lck, gtid );
+    ANNOTATE_TAS_ACQUIRED(lck);
 }
 
 static void
@@ -196,6 +199,7 @@ __kmp_release_tas_lock( kmp_tas_lock_t *lck, kmp_int32 gtid )
     KMP_MB();       /* Flush all pending memory write invalidates.  */
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_TAS_RELEASED(lck);
     KMP_ST_REL32( &(lck->lk.poll), DYNA_LOCK_FREE(tas) );
     KMP_MB();       /* Flush all pending memory write invalidates.  */
 
@@ -269,6 +273,7 @@ __kmp_acquire_nested_tas_lock( kmp_tas_lock_t *lck, kmp_int32 gtid )
     }
     else {
         __kmp_acquire_tas_lock_timed_template( lck, gtid );
+        ANNOTATE_TAS_ACQUIRED(lck);
         lck->lk.depth_locked = 1;
     }
 }
@@ -479,6 +484,7 @@ void
 __kmp_acquire_futex_lock( kmp_futex_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_futex_lock_timed_template( lck, gtid );
+    ANNOTATE_FUTEX_ACQUIRED(lck);
 }
 
 static void
@@ -525,6 +531,7 @@ __kmp_release_futex_lock( kmp_futex_lock_t *lck, kmp_int32 gtid )
       lck, lck->lk.poll, gtid ) );
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_FUTEX_RELEASED(lck);
 
     kmp_int32 poll_val = KMP_XCHG_FIXED32( & ( lck->lk.poll ), DYNA_LOCK_FREE(futex) );
 
@@ -612,6 +619,7 @@ __kmp_acquire_nested_futex_lock( kmp_futex_lock_t *lck, kmp_int32 gtid )
     }
     else {
         __kmp_acquire_futex_lock_timed_template( lck, gtid );
+	ANNOTATE_FUTEX_ACQUIRED(lck);
         lck->lk.depth_locked = 1;
     }
 }
@@ -773,6 +781,7 @@ void
 __kmp_acquire_ticket_lock( kmp_ticket_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_ticket_lock_timed_template( lck, gtid );
+    ANNOTATE_TICKET_ACQUIRED(lck);
 }
 
 static void
@@ -836,6 +845,7 @@ __kmp_release_ticket_lock( kmp_ticket_lock_t *lck, kmp_int32 gtid )
     KMP_MB();       /* Flush all pending memory write invalidates.  */
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_TICKET_RELEASED(lck);
     distance = ( TCR_4( lck->lk.next_ticket ) - TCR_4( lck->lk.now_serving ) );
 
     KMP_ST_REL32( &(lck->lk.now_serving), lck->lk.now_serving + 1 );
@@ -927,6 +937,7 @@ __kmp_acquire_nested_ticket_lock( kmp_ticket_lock_t *lck, kmp_int32 gtid )
     }
     else {
         __kmp_acquire_ticket_lock_timed_template( lck, gtid );
+        ANNOTATE_TICKET_ACQUIRED(lck);
         KMP_MB();
         lck->lk.depth_locked = 1;
         KMP_MB();
@@ -1379,6 +1390,7 @@ __kmp_acquire_queuing_lock( kmp_queuing_lock_t *lck, kmp_int32 gtid )
     KMP_DEBUG_ASSERT( gtid >= 0 );
 
     __kmp_acquire_queuing_lock_timed_template<false>( lck, gtid );
+    ANNOTATE_QUEUING_ACQUIRED(lck);
 }
 
 static void
@@ -1427,6 +1439,7 @@ __kmp_test_queuing_lock( kmp_queuing_lock_t *lck, kmp_int32 gtid )
         if ( KMP_COMPARE_AND_STORE_ACQ32( head_id_p, 0, -1 ) ) {
             KA_TRACE( 1000, ("__kmp_test_queuing_lock: T#%d exiting: holding lock\n", gtid ));
             KMP_FSYNC_ACQUIRED(lck);
+            ANNOTATE_QUEUING_ACQUIRED(lck);
             return TRUE;
         }
     }
@@ -1477,6 +1490,7 @@ __kmp_release_queuing_lock( kmp_queuing_lock_t *lck, kmp_int32 gtid )
     KMP_DEBUG_ASSERT( this_thr->th.th_next_waiting == 0 );
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_QUEUING_RELEASED(lck);
 
     while( 1 ) {
         kmp_int32 dequeued;
@@ -1674,6 +1688,7 @@ __kmp_acquire_nested_queuing_lock( kmp_queuing_lock_t *lck, kmp_int32 gtid )
     }
     else {
         __kmp_acquire_queuing_lock_timed_template<false>( lck, gtid );
+	ANNOTATE_QUEUING_ACQUIRED(lck);
         KMP_MB();
         lck->lk.depth_locked = 1;
         KMP_MB();
@@ -2313,6 +2328,7 @@ __kmp_acquire_adaptive_lock( kmp_adaptive_lock_t * lck, kmp_int32 gtid )
     __kmp_acquire_queuing_lock_timed_template<FALSE>( GET_QLK_PTR(lck), gtid );
     // We have acquired the base lock, so count that.
     KMP_INC_STAT(lck,nonSpeculativeAcquires );
+    ANNOTATE_QUEUING_ACQUIRED(lck);
 }
 
 static void
@@ -2598,6 +2614,7 @@ void
 __kmp_acquire_drdpa_lock( kmp_drdpa_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_drdpa_lock_timed_template( lck, gtid );
+    ANNOTATE_DRDPA_ACQUIRED(lck);
 }
 
 static void
@@ -2690,6 +2707,7 @@ __kmp_release_drdpa_lock( kmp_drdpa_lock_t *lck, kmp_int32 gtid )
     KA_TRACE(1000, ("__kmp_release_drdpa_lock: ticket #%lld released lock %p\n",
        ticket - 1, lck));
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_DRDPA_RELEASED(lck);
     KMP_ST_REL64(&(polls[ticket & mask].poll), ticket); // volatile store
 }
 
@@ -2793,6 +2811,7 @@ __kmp_acquire_nested_drdpa_lock( kmp_drdpa_lock_t *lck, kmp_int32 gtid )
     }
     else {
         __kmp_acquire_drdpa_lock_timed_template( lck, gtid );
+        ANNOTATE_DRDPA_ACQUIRED(lck);
         KMP_MB();
         lck->lk.depth_locked = 1;
         KMP_MB();
@@ -3904,12 +3923,15 @@ __kmp_user_lock_allocate( void **user_lock, kmp_int32 gtid,
 
     if ( __kmp_lock_pool == NULL ) {
         // Lock pool is empty. Allocate new memory.
+        /* ANNOTATION: Found no good way to express the syncronisation between allocation and usage, so ignore the allocation */
+        ANNOTATE_IGNORE_WRITES_BEGIN();
         if ( __kmp_num_locks_in_block <= 1 ) { // Tune this cutoff point.
             lck = (kmp_user_lock_p) __kmp_allocate( __kmp_user_lock_size );
         }
         else {
             lck = __kmp_lock_block_allocate();
         }
+        ANNOTATE_IGNORE_WRITES_END();
 
         // Insert lock in the table so that it can be freed in __kmp_cleanup,
         // and debugger has info on all allocated locks.
diff --git a/src/kmp_runtime.c b/src/kmp_runtime.c
index 4063523..b493497 100644
--- a/src/kmp_runtime.c
+++ b/src/kmp_runtime.c
@@ -53,6 +53,7 @@
 #include <process.h>
 #endif
 
+#include "dynamic_annotations.h"
 
 #if defined(KMP_GOMP_COMPAT)
 char const __kmp_version_alt_comp[] = KMP_VERSION_PREFIX "alternative compiler support: yes";
@@ -5333,6 +5334,7 @@ __kmp_reap_thread(
             /* Assume the threads are at the fork barrier here */
             KA_TRACE( 20, ("__kmp_reap_thread: releasing T#%d from fork barrier for reap\n", gtid ) );
             /* Need release fence here to prevent seg faults for tree forkjoin barrier (GEH) */
+	    ANNOTATE_HAPPENS_BEFORE(thread);
             kmp_flag_64 flag(&thread->th.th_bar[ bs_forkjoin_barrier ].bb.b_go, thread);
             __kmp_release_64(&flag);
         }; // if
diff --git a/src/kmp_tasking.c b/src/kmp_tasking.c
index c209b40..2ebc1d9 100644
--- a/src/kmp_tasking.c
+++ b/src/kmp_tasking.c
@@ -37,7 +37,7 @@
 #include "kmp_itt.h"
 #include "kmp_wait_release.h"
 
-
+#include "dynamic_annotations.h"
 
 /* ------------------------------------------------------------------------ */
 /* ------------------------------------------------------------------------ */
@@ -537,6 +537,7 @@ __kmp_free_task( kmp_int32 gtid, kmp_taskdata_t * taskdata, kmp_info_t * thread
     KMP_DEBUG_ASSERT( TCR_4(taskdata->td_incomplete_child_tasks) == 0 );
 
     taskdata->td_flags.freed = 1;
+    ANNOTATE_HAPPENS_BEFORE(taskdata);
     // deallocate the taskdata and shared variable blocks associated with this task
     #if USE_FAST_MEMORY
         __kmp_fast_free( thread, taskdata );
@@ -901,6 +902,7 @@ __kmp_task_alloc( ident_t *loc_ref, kmp_int32 gtid, kmp_tasking_flags_t *flags,
     #else /* ! USE_FAST_MEMORY */
     taskdata = (kmp_taskdata_t *) __kmp_thread_malloc( thread, shareds_offset + sizeof_shareds );
     #endif /* USE_FAST_MEMORY */
+    ANNOTATE_HAPPENS_AFTER(taskdata);
 
     task                      = KMP_TASKDATA_TO_TASK(taskdata);
 
@@ -999,6 +1001,7 @@ __kmp_task_alloc( ident_t *loc_ref, kmp_int32 gtid, kmp_tasking_flags_t *flags,
     KA_TRACE(20, ("__kmp_task_alloc(exit): T#%d created task %p parent=%p\n",
                   gtid, taskdata, taskdata->td_parent) );
 
+    ANNOTATE_HAPPENS_BEFORE(task);
     return task;
 }
 
@@ -1070,6 +1073,7 @@ __kmp_invoke_task( kmp_int32 gtid, kmp_task_t *task, kmp_taskdata_t * current_ta
     // Proxy tasks are not handled by the runtime
     if ( taskdata->td_flags.proxy != TASK_PROXY )
 #endif
+    ANNOTATE_HAPPENS_AFTER(task);
     __kmp_task_start( gtid, task, current_task );
 
 #if OMP_40_ENABLED
@@ -1109,6 +1113,8 @@ __kmp_invoke_task( kmp_int32 gtid, kmp_task_t *task, kmp_taskdata_t * current_ta
     // Proxy tasks are not handled by the runtime
     if ( taskdata->td_flags.proxy != TASK_PROXY )
 #endif
+
+       ANNOTATE_HAPPENS_BEFORE(taskdata->td_parent);
        __kmp_task_finish( gtid, task, current_task );
 
     KA_TRACE(30, ("__kmp_invoke_task(exit): T#%d completed task %p, resuming task %p\n",
@@ -1148,6 +1154,7 @@ __kmpc_omp_task_parts( ident_t *loc_ref, kmp_int32 gtid, kmp_task_t * new_task)
                   "loc=%p task=%p, return: TASK_CURRENT_NOT_QUEUED\n", gtid, loc_ref,
                   new_taskdata ) );
 
+    ANNOTATE_HAPPENS_BEFORE(new_task);
     return TASK_CURRENT_NOT_QUEUED;
 }
 
@@ -1179,7 +1186,7 @@ __kmp_omp_task( kmp_int32 gtid, kmp_task_t * new_task, bool serialize_immediate
         __kmp_invoke_task( gtid, new_task, current_task );
     }
 
-
+    ANNOTATE_HAPPENS_BEFORE(new_task);
     return TASK_CURRENT_NOT_QUEUED;
 }
 
@@ -1266,6 +1273,7 @@ __kmpc_omp_taskwait( ident_t *loc_ref, kmp_int32 gtid )
     KA_TRACE(10, ("__kmpc_omp_taskwait(exit): T#%d task %p finished waiting, "
                   "returning TASK_CURRENT_NOT_QUEUED\n", gtid, taskdata) );
 
+    ANNOTATE_HAPPENS_AFTER(taskdata);
     return TASK_CURRENT_NOT_QUEUED;
 }
 
@@ -1393,6 +1401,7 @@ __kmpc_end_taskgroup( ident_t* loc, int gtid )
     __kmp_thread_free( thread, taskgroup );
 
     KA_TRACE(10, ("__kmpc_end_taskgroup(exit): T#%d task %p finished waiting\n", gtid, taskdata) );
+    ANNOTATE_HAPPENS_AFTER(taskdata);
 }
 #endif
 
@@ -2157,8 +2166,10 @@ __kmp_realloc_task_threads_data( kmp_info_t *thread, kmp_task_team_t *task_team
                 // Make the initial allocate for threads_data array, and zero entries
                 // Cannot use __kmp_thread_calloc() because threads not around for
                 // kmp_reap_task_team( ).
+                ANNOTATE_IGNORE_WRITES_BEGIN();
                 *threads_data_p = (kmp_thread_data_t *)
                                   __kmp_allocate( nthreads * sizeof(kmp_thread_data_t) );
+                ANNOTATE_IGNORE_WRITES_END();
 #ifdef BUILD_TIED_TASK_STACK
                 // GEH: Figure out if this is the right thing to do
                 for (i = 0; i < nthreads; i++) {
diff --git a/src/makefile.mk b/src/makefile.mk
index 0545f7c..e127113 100644
--- a/src/makefile.mk
+++ b/src/makefile.mk
@@ -113,6 +113,7 @@ define curr_config
     CXXFLAGS=$(subst $(space),_,$(CXXFLAGS))
     FFLAGS=$(subst $(space),_,$(FFLAGS))
     LDFLAGS=$(subst $(space),_,$(LDFLAGS))
+    TSAN=$(tsan)
 endef
 # And check it.
 include $(tools_dir)src/common-checks.mk
@@ -712,6 +713,9 @@ ld-flags   += $(LDFLAGS)
 # --------------------------------------------------------------------------------------------------
 # Files.
 # --------------------------------------------------------------------------------------------------
+ifeq "$(tsan)" "enabled"
+  cpp-flags += -D DYNAMIC_ANNOTATIONS_ENABLED=1
+endif
 
 # Library files. These files participate in all kinds of library.
 lib_c_items :=      \
@@ -844,6 +848,9 @@ else
             _lib_item += mt
         endif
     endif
+    ifeq "$(tsan)" "enabled"
+	_lib_item += _tsan
+    endif
 endif
 # _lib_item is a list of space separated name parts. Remove spaces to form final name.
 lib_item = $(subst $(space),,$(_lib_item))
@@ -1342,12 +1349,16 @@ ifneq "$(arch)" "mic"
             endif
         else # lin
             ifeq "$(std_cpp_lib)" "1"
-                tt-c        = g++
+                tt-c        = $(cxx)
             else
-                tt-c        = gcc
+                tt-c        = $(c)
             endif
             # GCC on OS X* does not recognize -pthread.
             tt-c-flags  += -pthread
+            ifeq "$(tsan)" "enabled"
+                tt-c-flags  += -fsanitize=thread
+            endif
+
         endif
         tt-c-flags += -o $(tt-exe-file)
         ifneq "$(filter 32 32e 64,$(arch))" ""
diff --git a/src/z_Linux_util.c b/src/z_Linux_util.c
index 30d471d..7d1d535 100644
--- a/src/z_Linux_util.c
+++ b/src/z_Linux_util.c
@@ -51,6 +51,8 @@
 #include <sys/resource.h>
 #include <sys/syscall.h>
 
+#include "dynamic_annotations.h"
+
 #if KMP_OS_LINUX && !KMP_OS_CNK
 # include <sys/sysinfo.h>
 # if KMP_OS_LINUX && (KMP_ARCH_X86 || KMP_ARCH_X86_64 || KMP_ARCH_ARM || KMP_ARCH_AARCH64)
@@ -1667,6 +1669,7 @@ __kmp_suspend_initialize( void )
 static void
 __kmp_suspend_initialize_thread( kmp_info_t *th )
 {
+    ANNOTATE_HAPPENS_AFTER(&th->th.th_suspend_init_count);
     if ( th->th.th_suspend_init_count <= __kmp_fork_count ) {
         /* this means we haven't initialized the suspension pthread objects for this thread
            in this instance of the process */
@@ -1676,6 +1679,7 @@ __kmp_suspend_initialize_thread( kmp_info_t *th )
         status = pthread_mutex_init( &th->th.th_suspend_mx.m_mutex, & __kmp_suspend_mutex_attr );
         KMP_CHECK_SYSFAIL( "pthread_mutex_init", status );
         *(volatile int*)&th->th.th_suspend_init_count = __kmp_fork_count + 1;
+        ANNOTATE_HAPPENS_BEFORE(&th->th.th_suspend_init_count);
     };
 }
 
diff --git a/tools/build.pl b/tools/build.pl
index 82e159c..10974b7 100755
--- a/tools/build.pl
+++ b/tools/build.pl
@@ -84,12 +84,13 @@ my $opts = {
     "omp-version"     => { targets => "rtl",               base => 0, parms => { 40      => "", 30        => "", 41 => "*"    }, suffix => sub { $_[ 0 ];                       } },
     "coverage"        => { targets => "rtl",               base => 0, parms => { off     => "*", on        => ""              }, suffix => sub { $_[ 0 ] eq "on" ? "c1" : "c0"; } },
     "stats"           => { targets => "rtl",               base => 0, parms => { off     => "*", on        => ""              }, suffix => sub { $_[ 0 ] eq "on" ? "s1" : "s0"; } },
+    "tsan"    => { targets => "rtl",         base => 0, parms => { enabled => "", disabled => "*"               }, suffix => sub { "" } },
 };
 my $synonyms = {
     "debug" => [ qw{ dbg debg } ],
 };
 # This array specifies order of options to process, so it cannot be initialized with keys( %$opts ).
-my @all_opts   = qw{ target version lib-type link-type mode omp-version coverage stats };
+my @all_opts   = qw{ target version lib-type link-type mode omp-version coverage stats tsan};
 # This is the list of base options.
 my @base_opts  = grep( $opts->{ $_ }->{ base } == 1, @all_opts );
 # This is the list of extra options.
@@ -290,6 +291,7 @@ sub enqueue_jobs($$@) {
                     "VERSION=" . $set->{ version },
                     "suffix=" . $suf,
                     "stats=" . $set->{ stats },
+		    "tsan=" . $set->{ "tsan" },
                     @goals,
                 ],
                 build_dir  => $build_dir
