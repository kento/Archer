diff -rupN libomp_oss_orig/src/dynamic_annotations.h libomp_oss/src/dynamic_annotations.h
--- libomp_oss_orig/src/dynamic_annotations.h	1969-12-31 16:00:00.000000000 -0800
+++ libomp_oss/src/dynamic_annotations.h	2014-09-23 10:38:43.000000000 -0700
@@ -0,0 +1,661 @@
+/* Copyright (c) 2011, Google Inc.
+* All rights reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+* * Redistributions of source code must retain the above copyright
+* notice, this list of conditions and the following disclaimer.
+* * Neither the name of Google Inc. nor the names of its
+* contributors may be used to endorse or promote products derived from
+* this software without specific prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+* "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+* LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+* A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+* OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+* SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+* LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+* DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+* THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+* (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+/* This file defines dynamic annotations for use with dynamic analysis
+tool such as valgrind, PIN, etc.
+
+Dynamic annotation is a source code annotation that affects
+the generated code (that is, the annotation is not a comment).
+Each such annotation is attached to a particular
+instruction and/or to a particular object (address) in the program.
+
+The annotations that should be used by users are macros in all upper-case
+(e.g., ANNOTATE_NEW_MEMORY).
+
+Actual implementation of these macros may differ depending on the
+dynamic analysis tool being used.
+
+See http://code.google.com/p/data-race-test/ for more information.
+
+This file supports the following dynamic analysis tools:
+- None (DYNAMIC_ANNOTATIONS_ENABLED is not defined or zero).
+Macros are defined empty.
+- ThreadSanitizer, Helgrind, DRD (DYNAMIC_ANNOTATIONS_ENABLED is 1).
+Macros are defined as calls to non-inlinable empty functions
+that are intercepted by Valgrind. */
+
+#ifndef __DYNAMIC_ANNOTATIONS_H__
+#define __DYNAMIC_ANNOTATIONS_H__
+
+#ifndef DYNAMIC_ANNOTATIONS_PREFIX
+# define DYNAMIC_ANNOTATIONS_PREFIX
+#endif
+
+// #ifndef DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND
+// # define DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND 1
+// #endif
+
+#ifdef DYNAMIC_ANNOTATIONS_WANT_ATTRIBUTE_WEAK
+# ifdef __GNUC__
+# define DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK __attribute__((weak))
+# else
+/* TODO(glider): for Windows support we may want to change this macro in order
+to prepend __declspec(selectany) to the annotations' declarations. */
+# error weak annotations are not supported for your compiler
+# endif
+#else
+# define DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK
+#endif
+
+/* The following preprocessor magic prepends the value of
+DYNAMIC_ANNOTATIONS_PREFIX to annotation function names. */
+#define DYNAMIC_ANNOTATIONS_GLUE0(A, B) A##B
+#define DYNAMIC_ANNOTATIONS_GLUE(A, B) DYNAMIC_ANNOTATIONS_GLUE0(A, B)
+#define DYNAMIC_ANNOTATIONS_NAME(name) \
+DYNAMIC_ANNOTATIONS_GLUE(DYNAMIC_ANNOTATIONS_PREFIX, name)
+
+//#undef DYNAMIC_ANNOTATIONS_ENABLED
+//# define DYNAMIC_ANNOTATIONS_ENABLED 0
+
+#ifndef DYNAMIC_ANNOTATIONS_ENABLED
+# define DYNAMIC_ANNOTATIONS_ENABLED 0
+#endif
+
+#if DYNAMIC_ANNOTATIONS_ENABLED != 0
+
+  /* -------------------------------------------------------------
+Annotations useful when implementing condition variables such as CondVar,
+using conditional critical sections (Await/LockWhen) and when constructing
+user-defined synchronization mechanisms.
+
+The annotations ANNOTATE_HAPPENS_BEFORE() and ANNOTATE_HAPPENS_AFTER() can
+be used to define happens-before arcs in user-defined synchronization
+mechanisms: the race detector will infer an arc from the former to the
+latter when they share the same argument pointer.
+
+Example 1 (reference counting):
+
+void Unref() {
+ANNOTATE_HAPPENS_BEFORE(&refcount_);
+if (AtomicDecrementByOne(&refcount_) == 0) {
+ANNOTATE_HAPPENS_AFTER(&refcount_);
+delete this;
+}
+}
+
+Example 2 (message queue):
+
+void MyQueue::Put(Type *e) {
+MutexLock lock(&mu_);
+ANNOTATE_HAPPENS_BEFORE(e);
+PutElementIntoMyQueue(e);
+}
+
+Type *MyQueue::Get() {
+MutexLock lock(&mu_);
+Type *e = GetElementFromMyQueue();
+ANNOTATE_HAPPENS_AFTER(e);
+return e;
+}
+
+Note: when possible, please use the existing reference counting and message
+queue implementations instead of inventing new ones. */
+
+  /* Report that wait on the condition variable at address "cv" has succeeded
+and the lock at address "lock" is held. */
+#define ANNOTATE_CONDVAR_LOCK_WAIT(cv, lock) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarWait)(__FILE__, __LINE__, cv, lock)
+
+  /* Report that wait on the condition variable at "cv" has succeeded. Variant
+w/o lock. */
+#define ANNOTATE_CONDVAR_WAIT(cv) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarWait)(__FILE__, __LINE__, cv, NULL)
+
+  /* Report that we are about to signal on the condition variable at address
+"cv". */
+#define ANNOTATE_CONDVAR_SIGNAL(cv) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignal)(__FILE__, __LINE__, cv)
+
+  /* Report that we are about to signal_all on the condition variable at address
+"cv". */
+#define ANNOTATE_CONDVAR_SIGNAL_ALL(cv) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignalAll)(__FILE__, __LINE__, cv)
+
+  /* Annotations for user-defined synchronization mechanisms. */
+  #define ANNOTATE_HAPPENS_BEFORE(obj) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensBefore)(__FILE__, __LINE__, obj)
+#define ANNOTATE_HAPPENS_AFTER(obj) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensAfter)(__FILE__, __LINE__, obj)
+
+  /* DEPRECATED. Don't use it. */
+  #define ANNOTATE_PUBLISH_MEMORY_RANGE(pointer, size) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePublishMemoryRange)(__FILE__, __LINE__, \
+pointer, size)
+
+  /* DEPRECATED. Don't use it. */
+  #define ANNOTATE_UNPUBLISH_MEMORY_RANGE(pointer, size) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateUnpublishMemoryRange)(__FILE__, __LINE__, \
+pointer, size)
+
+  /* DEPRECATED. Don't use it. */
+  #define ANNOTATE_SWAP_MEMORY_RANGE(pointer, size) \
+do { \
+ANNOTATE_UNPUBLISH_MEMORY_RANGE(pointer, size); \
+ANNOTATE_PUBLISH_MEMORY_RANGE(pointer, size); \
+} while (0)
+
+  /* Instruct the tool to create a happens-before arc between mu->Unlock() and
+mu->Lock(). This annotation may slow down the race detector and hide real
+races. Normally it is used only when it would be difficult to annotate each
+of the mutex's critical sections individually using the annotations above.
+This annotation makes sense only for hybrid race detectors. For pure
+happens-before detectors this is a no-op. For more details see
+http://code.google.com/p/data-race-test/wiki/PureHappensBeforeVsHybrid . */
+#define ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX(mu) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsUsedAsCondVar)(__FILE__, __LINE__, \
+mu)
+
+  /* Opposite to ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX.
+Instruct the tool to NOT create h-b arcs between Unlock and Lock, even in
+pure happens-before mode. For a hybrid mode this is a no-op. */
+#define ANNOTATE_NOT_HAPPENS_BEFORE_MUTEX(mu) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsNotPHB)(__FILE__, __LINE__, mu)
+
+  /* Deprecated. Use ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX. */
+  #define ANNOTATE_MUTEX_IS_USED_AS_CONDVAR(mu) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsUsedAsCondVar)(__FILE__, __LINE__, \
+mu)
+
+  /* -------------------------------------------------------------
+Annotations useful when defining memory allocators, or when memory that
+was protected in one way starts to be protected in another. */
+
+  /* Report that a new memory at "address" of size "size" has been allocated.
+This might be used when the memory has been retrieved from a free list and
+is about to be reused, or when a the locking discipline for a variable
+changes. */
+#define ANNOTATE_NEW_MEMORY(address, size) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateNewMemory)(__FILE__, __LINE__, address, \
+size)
+
+  /* -------------------------------------------------------------
+Annotations useful when defining FIFO queues that transfer data between
+threads. */
+
+  /* Report that the producer-consumer queue (such as ProducerConsumerQueue) at
+address "pcq" has been created. The ANNOTATE_PCQ_* annotations
+should be used only for FIFO queues. For non-FIFO queues use
+ANNOTATE_HAPPENS_BEFORE (for put) and ANNOTATE_HAPPENS_AFTER (for get). */
+#define ANNOTATE_PCQ_CREATE(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQCreate)(__FILE__, __LINE__, pcq)
+
+  /* Report that the queue at address "pcq" is about to be destroyed. */
+  #define ANNOTATE_PCQ_DESTROY(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQDestroy)(__FILE__, __LINE__, pcq)
+
+  /* Report that we are about to put an element into a FIFO queue at address
+"pcq". */
+#define ANNOTATE_PCQ_PUT(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQPut)(__FILE__, __LINE__, pcq)
+
+  /* Report that we've just got an element from a FIFO queue at address
+"pcq". */
+#define ANNOTATE_PCQ_GET(pcq) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQGet)(__FILE__, __LINE__, pcq)
+
+  /* -------------------------------------------------------------
+Annotations that suppress errors. It is usually better to express the
+program's synchronization using the other annotations, but these can
+be used when all else fails. */
+
+  /* Report that we may have a benign race at "pointer", with size
+"sizeof(*(pointer))". "pointer" must be a non-void* pointer. Insert at the
+point where "pointer" has been allocated, preferably close to the point
+where the race happens. See also ANNOTATE_BENIGN_RACE_STATIC. */
+#define ANNOTATE_BENIGN_RACE(pointer, description) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRaceSized)(__FILE__, __LINE__, \
+pointer, sizeof(*(pointer)), description)
+
+  /* Same as ANNOTATE_BENIGN_RACE(address, description), but applies to
+the memory range [address, address+size). */
+#define ANNOTATE_BENIGN_RACE_SIZED(address, size, description) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRaceSized)(__FILE__, __LINE__, \
+address, size, description)
+
+  /* Request the analysis tool to ignore all reads in the current thread
+until ANNOTATE_IGNORE_READS_END is called.
+Useful to ignore intentional racey reads, while still checking
+other reads and all writes.
+See also ANNOTATE_UNPROTECTED_READ. */
+#define ANNOTATE_IGNORE_READS_BEGIN() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsBegin)(__FILE__, __LINE__)
+
+  /* Stop ignoring reads. */
+  #define ANNOTATE_IGNORE_READS_END() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsEnd)(__FILE__, __LINE__)
+
+  /* Similar to ANNOTATE_IGNORE_READS_BEGIN, but ignore writes. */
+  #define ANNOTATE_IGNORE_WRITES_BEGIN() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesBegin)(__FILE__, __LINE__)
+
+  /* Stop ignoring writes. */
+  #define ANNOTATE_IGNORE_WRITES_END() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesEnd)(__FILE__, __LINE__)
+
+  /* Start ignoring all memory accesses (reads and writes). */
+  #define ANNOTATE_IGNORE_READS_AND_WRITES_BEGIN() \
+do {\
+ANNOTATE_IGNORE_READS_BEGIN();\
+ANNOTATE_IGNORE_WRITES_BEGIN();\
+}while(0)\
+
+  /* Stop ignoring all memory accesses. */
+  #define ANNOTATE_IGNORE_READS_AND_WRITES_END() \
+do {\
+ANNOTATE_IGNORE_WRITES_END();\
+ANNOTATE_IGNORE_READS_END();\
+}while(0)\
+
+  /* Similar to ANNOTATE_IGNORE_READS_BEGIN, but ignore synchronization events:
+RWLOCK* and CONDVAR*. */
+#define ANNOTATE_IGNORE_SYNC_BEGIN() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncBegin)(__FILE__, __LINE__)
+
+  /* Stop ignoring sync events. */
+  #define ANNOTATE_IGNORE_SYNC_END() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncEnd)(__FILE__, __LINE__)
+
+
+  /* Enable (enable!=0) or disable (enable==0) race detection for all threads.
+This annotation could be useful if you want to skip expensive race analysis
+during some period of program execution, e.g. during initialization. */
+#define ANNOTATE_ENABLE_RACE_DETECTION(enable) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateEnableRaceDetection)(__FILE__, __LINE__, \
+enable)
+
+  /* -------------------------------------------------------------
+Annotations useful for debugging. */
+
+  /* Request to trace every access to "address". */
+  #define ANNOTATE_TRACE_MEMORY(address) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateTraceMemory)(__FILE__, __LINE__, address)
+
+  /* Report the current thread name to a race detector. */
+  #define ANNOTATE_THREAD_NAME(name) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateThreadName)(__FILE__, __LINE__, name)
+
+  /* -------------------------------------------------------------
+Annotations useful when implementing locks. They are not
+normally needed by modules that merely use locks.
+The "lock" argument is a pointer to the lock object. */
+
+  /* Report that a lock has been created at address "lock". */
+  #define ANNOTATE_RWLOCK_CREATE(lock) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockCreate)(__FILE__, __LINE__, lock)
+
+  /* Report that the lock at address "lock" is about to be destroyed. */
+  #define ANNOTATE_RWLOCK_DESTROY(lock) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockDestroy)(__FILE__, __LINE__, lock)
+
+  /* Report that the lock at address "lock" has been acquired.
+is_w=1 for writer lock, is_w=0 for reader lock. */
+#define ANNOTATE_RWLOCK_ACQUIRED(lock, is_w) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockAcquired)(__FILE__, __LINE__, lock, \
+is_w)
+
+  /* Report that the lock at address "lock" is about to be released. */
+  #define ANNOTATE_RWLOCK_RELEASED(lock, is_w) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockReleased)(__FILE__, __LINE__, lock, \
+is_w)
+
+  /* -------------------------------------------------------------
+Annotations useful when implementing barriers. They are not
+normally needed by modules that merely use barriers.
+The "barrier" argument is a pointer to the barrier object. */
+
+  /* Report that the "barrier" has been initialized with initial "count".
+If 'reinitialization_allowed' is true, initialization is allowed to happen
+multiple times w/o calling barrier_destroy() */
+#define ANNOTATE_BARRIER_INIT(barrier, count, reinitialization_allowed) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierInit)(__FILE__, __LINE__, barrier, \
+count, reinitialization_allowed)
+
+  /* Report that we are about to enter barrier_wait("barrier"). */
+  #define ANNOTATE_BARRIER_WAIT_BEFORE(barrier) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitBefore)(__FILE__, __LINE__, \
+barrier)
+
+  /* Report that we just exited barrier_wait("barrier"). */
+  #define ANNOTATE_BARRIER_WAIT_AFTER(barrier) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitAfter)(__FILE__, __LINE__, \
+barrier)
+
+  /* Report that the "barrier" has been destroyed. */
+  #define ANNOTATE_BARRIER_DESTROY(barrier) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierDestroy)(__FILE__, __LINE__, \
+barrier)
+
+  /* -------------------------------------------------------------
+Annotations useful for testing race detectors. */
+
+  /* Report that we expect a race on the variable at "address".
+Use only in unit tests for a race detector. */
+#define ANNOTATE_EXPECT_RACE(address, description) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateExpectRace)(__FILE__, __LINE__, address, \
+description)
+
+#define ANNOTATE_FLUSH_EXPECTED_RACES() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushExpectedRaces)(__FILE__, __LINE__)
+
+  /* A no-op. Insert where you like to test the interceptors. */
+  #define ANNOTATE_NO_OP(arg) \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateNoOp)(__FILE__, __LINE__, arg)
+
+  /* Force the race detector to flush its state. The actual effect depends on
+* the implementation of the detector. */
+#define ANNOTATE_FLUSH_STATE() \
+DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushState)(__FILE__, __LINE__)
+
+
+#else /* DYNAMIC_ANNOTATIONS_ENABLED == 0 */
+
+#define ANNOTATE_RWLOCK_CREATE(lock) /* empty */
+#define ANNOTATE_RWLOCK_DESTROY(lock) /* empty */
+#define ANNOTATE_RWLOCK_ACQUIRED(lock, is_w) /* empty */
+#define ANNOTATE_RWLOCK_RELEASED(lock, is_w) /* empty */
+#define ANNOTATE_BARRIER_INIT(barrier, count, reinitialization_allowed) /* */
+#define ANNOTATE_BARRIER_WAIT_BEFORE(barrier) /* empty */
+#define ANNOTATE_BARRIER_WAIT_AFTER(barrier) /* empty */
+#define ANNOTATE_BARRIER_DESTROY(barrier) /* empty */
+#define ANNOTATE_CONDVAR_LOCK_WAIT(cv, lock) /* empty */
+#define ANNOTATE_CONDVAR_WAIT(cv) /* empty */
+#define ANNOTATE_CONDVAR_SIGNAL(cv) /* empty */
+#define ANNOTATE_CONDVAR_SIGNAL_ALL(cv) /* empty */
+#define ANNOTATE_HAPPENS_BEFORE(obj) /* empty */
+#define ANNOTATE_HAPPENS_AFTER(obj) /* empty */
+#define ANNOTATE_PUBLISH_MEMORY_RANGE(address, size) /* empty */
+#define ANNOTATE_UNPUBLISH_MEMORY_RANGE(address, size) /* empty */
+#define ANNOTATE_SWAP_MEMORY_RANGE(address, size) /* empty */
+#define ANNOTATE_PCQ_CREATE(pcq) /* empty */
+#define ANNOTATE_PCQ_DESTROY(pcq) /* empty */
+#define ANNOTATE_PCQ_PUT(pcq) /* empty */
+#define ANNOTATE_PCQ_GET(pcq) /* empty */
+#define ANNOTATE_NEW_MEMORY(address, size) /* empty */
+#define ANNOTATE_EXPECT_RACE(address, description) /* empty */
+#define ANNOTATE_FLUSH_EXPECTED_RACES(address, description) /* empty */
+#define ANNOTATE_BENIGN_RACE(address, description) /* empty */
+#define ANNOTATE_BENIGN_RACE_SIZED(address, size, description) /* empty */
+#define ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX(mu) /* empty */
+#define ANNOTATE_MUTEX_IS_USED_AS_CONDVAR(mu) /* empty */
+#define ANNOTATE_TRACE_MEMORY(arg) /* empty */
+#define ANNOTATE_THREAD_NAME(name) /* empty */
+#define ANNOTATE_IGNORE_READS_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_READS_END() /* empty */
+#define ANNOTATE_IGNORE_WRITES_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_WRITES_END() /* empty */
+#define ANNOTATE_IGNORE_READS_AND_WRITES_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_READS_AND_WRITES_END() /* empty */
+#define ANNOTATE_IGNORE_SYNC_BEGIN() /* empty */
+#define ANNOTATE_IGNORE_SYNC_END() /* empty */
+#define ANNOTATE_ENABLE_RACE_DETECTION(enable) /* empty */
+#define ANNOTATE_NO_OP(arg) /* empty */
+#define ANNOTATE_FLUSH_STATE() /* empty */
+
+#endif /* DYNAMIC_ANNOTATIONS_ENABLED */
+
+//#undef ANNOTATE_HAPPENS_BEFORE
+//#undef ANNOTATE_HAPPENS_AFTER
+//#define ANNOTATE_HAPPENS_BEFORE(obj) /* empty */
+//#define ANNOTATE_HAPPENS_AFTER(obj) /* empty */
+
+/* specify the locks to be instrumented */
+#define ANNOTATE_QUEUING
+ #define ANNOTATE_TICKET
+#define ANNOTATE_FUTEX
+ #define ANNOTATE_TAS
+#define ANNOTATE_DRDPA
+
+#ifdef ANNOTATE_QUEUING
+#define ANNOTATE_QUEUING_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_QUEUING_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_QUEUING_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_QUEUING_CREATE(lck) (void)0
+#define ANNOTATE_QUEUING_RELEASED(lck) (void)0
+#define ANNOTATE_QUEUING_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_TICKET
+#define ANNOTATE_TICKET_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_TICKET_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_TICKET_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_TICKET_CREATE(lck) (void)0
+#define ANNOTATE_TICKET_RELEASED(lck) (void)0
+#define ANNOTATE_TICKET_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_FUTEX
+#define ANNOTATE_FUTEX_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_FUTEX_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_FUTEX_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_FUTEX_CREATE(lck) (void)0
+#define ANNOTATE_FUTEX_RELEASED(lck) (void)0
+#define ANNOTATE_FUTEX_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_TAS
+#define ANNOTATE_TAS_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_TAS_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_TAS_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_TAS_CREATE(lck) (void)0
+#define ANNOTATE_TAS_RELEASED(lck) (void)0
+#define ANNOTATE_TAS_ACQUIRED(lck) (void)0
+#endif
+
+#ifdef ANNOTATE_DRDPA
+#define ANNOTATE_DRDPA_CREATE(lck) ANNOTATE_RWLOCK_CREATE((void *) lck)
+#define ANNOTATE_DRDPA_RELEASED(lck) ANNOTATE_RWLOCK_RELEASED((void *) lck, 1)
+#define ANNOTATE_DRDPA_ACQUIRED(lck) ANNOTATE_RWLOCK_ACQUIRED((void *) lck, 1)
+#else
+#define ANNOTATE_DRDPA_CREATE(lck) (void)0
+#define ANNOTATE_DRDPA_RELEASED(lck) (void)0
+#define ANNOTATE_DRDPA_ACQUIRED(lck) (void)0
+#endif
+
+
+/* Use the macros above rather than using these functions directly. */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockCreate)(
+    const char *file, int line,
+    const volatile void *lock) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockDestroy)(
+    const char *file, int line,
+    const volatile void *lock) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockAcquired)(
+    const char *file, int line,
+    const volatile void *lock, long is_w) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateRWLockReleased)(
+    const char *file, int line,
+    const volatile void *lock, long is_w) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierInit)(
+    const char *file, int line, const volatile void *barrier, long count,
+    long reinitialization_allowed) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitBefore)(
+    const char *file, int line,
+    const volatile void *barrier) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierWaitAfter)(
+    const char *file, int line,
+    const volatile void *barrier) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBarrierDestroy)(
+    const char *file, int line,
+    const volatile void *barrier) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarWait)(
+    const char *file, int line, const volatile void *cv,
+    const volatile void *lock) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignal)(
+    const char *file, int line,
+    const volatile void *cv) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateCondVarSignalAll)(
+    const char *file, int line,
+    const volatile void *cv) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensBefore)(
+    const char *file, int line,
+    const volatile void *obj) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateHappensAfter)(
+    const char *file, int line,
+    const volatile void *obj) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePublishMemoryRange)(
+    const char *file, int line,
+    const volatile void *address, long size) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateUnpublishMemoryRange)(
+    const char *file, int line,
+    const volatile void *address, long size) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQCreate)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQDestroy)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQPut)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotatePCQGet)(
+    const char *file, int line,
+    const volatile void *pcq) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateNewMemory)(
+    const char *file, int line,
+    const volatile void *mem, long size) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateExpectRace)(
+    const char *file, int line, const volatile void *mem,
+    const char *description) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushExpectedRaces)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRace)(
+    const char *file, int line, const volatile void *mem,
+    const char *description) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateBenignRaceSized)(
+    const char *file, int line, const volatile void *mem, long size,
+    const char *description) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsUsedAsCondVar)(
+    const char *file, int line,
+    const volatile void *mu) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateMutexIsNotPHB)(
+    const char *file, int line,
+    const volatile void *mu) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateTraceMemory)(
+    const char *file, int line,
+    const volatile void *arg) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateThreadName)(
+    const char *file, int line,
+    const char *name) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsBegin)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreReadsEnd)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesBegin)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreWritesEnd)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncBegin)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateIgnoreSyncEnd)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateEnableRaceDetection)(
+    const char *file, int line, int enable) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateNoOp)(
+    const char *file, int line,
+    const volatile void *arg) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+void DYNAMIC_ANNOTATIONS_NAME(AnnotateFlushState)(
+    const char *file, int line) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+
+#if DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND == 1
+/* Return non-zero value if running under valgrind.
+
+If "valgrind.h" is included into dynamic_annotations.c,
+the regular valgrind mechanism will be used.
+See http://valgrind.org/docs/manual/manual-core-adv.html about
+RUNNING_ON_VALGRIND and other valgrind "client requests".
+The file "valgrind.h" may be obtained by doing
+svn co svn://svn.valgrind.org/valgrind/trunk/include
+
+If for some reason you can't use "valgrind.h" or want to fake valgrind,
+there are two ways to make this function return non-zero:
+- Use environment variable: export RUNNING_ON_VALGRIND=1
+- Make your tool intercept the function RunningOnValgrind() and
+change its return value.
+*/
+int RunningOnValgrind(void) DYNAMIC_ANNOTATIONS_ATTRIBUTE_WEAK;
+#endif /* DYNAMIC_ANNOTATIONS_PROVIDE_RUNNING_ON_VALGRIND == 1 */
+
+#ifdef __cplusplus
+}
+#endif
+
+#if DYNAMIC_ANNOTATIONS_ENABLED != 0 && defined(__cplusplus)
+
+  /* ANNOTATE_UNPROTECTED_READ is the preferred way to annotate racey reads.
+
+Instead of doing
+ANNOTATE_IGNORE_READS_BEGIN();
+... = x;
+ANNOTATE_IGNORE_READS_END();
+one can use
+... = ANNOTATE_UNPROTECTED_READ(x); */
+  template <class T>
+  inline T ANNOTATE_UNPROTECTED_READ(const volatile T &x) {
+    ANNOTATE_IGNORE_READS_BEGIN();
+    T res = x;
+    ANNOTATE_IGNORE_READS_END();
+    return res;
+  }
+  /* Apply ANNOTATE_BENIGN_RACE_SIZED to a static variable. */
+  #define ANNOTATE_BENIGN_RACE_STATIC(static_var, description) \
+namespace { \
+class static_var ## _annotator { \
+public: \
+static_var ## _annotator() { \
+ANNOTATE_BENIGN_RACE_SIZED(&static_var, \
+sizeof(static_var), \
+# static_var ": " description); \
+} \
+}; \
+static static_var ## _annotator the ## static_var ## _annotator;\
+}
+#else /* DYNAMIC_ANNOTATIONS_ENABLED == 0 */
+
+#define ANNOTATE_UNPROTECTED_READ(x) (x)
+#define ANNOTATE_BENIGN_RACE_STATIC(static_var, description) /* empty */
+
+#endif /* DYNAMIC_ANNOTATIONS_ENABLED */
+
+#endif /* __DYNAMIC_ANNOTATIONS_H__ */
diff -rupN libomp_oss_orig/src/kmp_lock.cpp libomp_oss/src/kmp_lock.cpp
--- libomp_oss_orig/src/kmp_lock.cpp	2013-12-13 10:08:47.000000000 -0800
+++ libomp_oss/src/kmp_lock.cpp	2014-09-23 10:38:44.000000000 -0700
@@ -42,6 +42,8 @@
 #include "kmp_lock.h"
 #include "kmp_io.h"
 
+#include "dynamic_annotations.h"
+
 #if KMP_OS_LINUX && (KMP_ARCH_X86 || KMP_ARCH_X86_64 || KMP_ARCH_ARM)
 # include <unistd.h>
 # include <sys/syscall.h>
@@ -177,6 +179,7 @@ void
 __kmp_acquire_tas_lock( kmp_tas_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_tas_lock_timed_template( lck, gtid );
+        ANNOTATE_TAS_ACQUIRED(lck);
 }
 
 static void
@@ -225,6 +228,7 @@ __kmp_release_tas_lock( kmp_tas_lock_t *
     KMP_MB();       /* Flush all pending memory write invalidates.  */
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_TAS_RELEASED(lck);
     KMP_ST_REL32( &(lck->lk.poll), 0 );
 
     KMP_MB();       /* Flush all pending memory write invalidates.  */
@@ -303,6 +307,7 @@ __kmp_acquire_nested_tas_lock( kmp_tas_l
     }
     else {
         __kmp_acquire_tas_lock_timed_template( lck, gtid );
+        ANNOTATE_TAS_ACQUIRED(lck);
         lck->lk.depth_locked = 1;
     }
 }
@@ -520,6 +525,7 @@ void
 __kmp_acquire_futex_lock( kmp_futex_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_futex_lock_timed_template( lck, gtid );
+    ANNOTATE_FUTEX_ACQUIRED(lck);
 }
 
 static void
@@ -570,6 +576,7 @@ __kmp_release_futex_lock( kmp_futex_lock
       lck, lck->lk.poll, gtid ) );
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_FUTEX_RELEASED(lck);
 
     kmp_int32 poll_val = KMP_XCHG_FIXED32( & ( lck->lk.poll ), 0 );
 
@@ -661,6 +668,7 @@ __kmp_acquire_nested_futex_lock( kmp_fut
     }
     else {
         __kmp_acquire_futex_lock_timed_template( lck, gtid );
+        ANNOTATE_FUTEX_ACQUIRED(lck);
         lck->lk.depth_locked = 1;
     }
 }
@@ -832,6 +840,7 @@ void
 __kmp_acquire_ticket_lock( kmp_ticket_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_ticket_lock_timed_template( lck, gtid );
+    ANNOTATE_TICKET_ACQUIRED(lck);
 }
 
 static void
@@ -901,6 +910,7 @@ __kmp_release_ticket_lock( kmp_ticket_lo
     KMP_MB();       /* Flush all pending memory write invalidates.  */
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_TICKET_RELEASED(lck);
     distance = ( TCR_4( lck->lk.next_ticket ) - TCR_4( lck->lk.now_serving ) );
 
     KMP_ST_REL32( &(lck->lk.now_serving), lck->lk.now_serving + 1 );
@@ -996,6 +1006,7 @@ __kmp_acquire_nested_ticket_lock( kmp_ti
     }
     else {
         __kmp_acquire_ticket_lock_timed_template( lck, gtid );
+        ANNOTATE_TICKET_ACQUIRED(lck);
         KMP_MB();
         lck->lk.depth_locked = 1;
         KMP_MB();
@@ -1456,6 +1467,7 @@ __kmp_acquire_queuing_lock( kmp_queuing_
     KMP_DEBUG_ASSERT( gtid >= 0 );
 
     __kmp_acquire_queuing_lock_timed_template<false>( lck, gtid );
+    ANNOTATE_QUEUING_ACQUIRED(lck);
 }
 
 static void
@@ -1508,6 +1520,7 @@ __kmp_test_queuing_lock( kmp_queuing_loc
         if ( KMP_COMPARE_AND_STORE_ACQ32( head_id_p, 0, -1 ) ) {
             KA_TRACE( 1000, ("__kmp_test_queuing_lock: T#%d exiting: holding lock\n", gtid ));
             KMP_FSYNC_ACQUIRED(lck);
+            ANNOTATE_QUEUING_ACQUIRED(lck);
             return TRUE;
         }
     }
@@ -1560,6 +1573,7 @@ __kmp_release_queuing_lock( kmp_queuing_
     KMP_DEBUG_ASSERT( this_thr->th.th_next_waiting == 0 );
 
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_QUEUING_RELEASED(lck);
 
     while( 1 ) {
         kmp_int32 dequeued;
@@ -1761,6 +1775,7 @@ __kmp_acquire_nested_queuing_lock( kmp_q
     }
     else {
         __kmp_acquire_queuing_lock_timed_template<false>( lck, gtid );
+         ANNOTATE_QUEUING_ACQUIRED(lck);
         KMP_MB();
         lck->lk.depth_locked = 1;
         KMP_MB();
@@ -2409,6 +2424,7 @@ __kmp_acquire_adaptive_lock( kmp_queuing
     __kmp_acquire_queuing_lock_timed_template<FALSE>( lck, gtid );
     // We have acquired the base lock, so count that.
     KMP_INC_STAT(lck,nonSpeculativeAcquires );
+    ANNOTATE_QUEUING_ACQUIRED(lck);
 }
 
 static void
@@ -2705,6 +2721,7 @@ void
 __kmp_acquire_drdpa_lock( kmp_drdpa_lock_t *lck, kmp_int32 gtid )
 {
     __kmp_acquire_drdpa_lock_timed_template( lck, gtid );
+    ANNOTATE_DRDPA_ACQUIRED(lck);
 }
 
 static void
@@ -2803,6 +2820,7 @@ __kmp_release_drdpa_lock( kmp_drdpa_lock
     KA_TRACE(1000, ("__kmp_release_drdpa_lock: ticket #%lld released lock %p\n",
        ticket - 1, lck));
     KMP_FSYNC_RELEASING(lck);
+    ANNOTATE_DRDPA_RELEASED(lck);
     KMP_ST_REL64(&(polls[ticket & mask].poll), ticket); // volatile store
 }
 
@@ -2910,6 +2928,7 @@ __kmp_acquire_nested_drdpa_lock( kmp_drd
     }
     else {
         __kmp_acquire_drdpa_lock_timed_template( lck, gtid );
+        ANNOTATE_DRDPA_ACQUIRED(lck);
         KMP_MB();
         lck->lk.depth_locked = 1;
         KMP_MB();
@@ -3627,12 +3646,15 @@ __kmp_user_lock_allocate( void **user_lo
 
     if ( __kmp_lock_pool == NULL ) {
         // Lock pool is empty. Allocate new memory.
+        /* ANNOTATION: Found no good way to express the syncronisation between allocation and usage, so ignore the allocation */
+        ANNOTATE_IGNORE_WRITES_BEGIN(); 
         if ( __kmp_num_locks_in_block <= 1 ) { // Tune this cutoff point.
             lck = (kmp_user_lock_p) __kmp_allocate( __kmp_user_lock_size );
         }
         else {
             lck = __kmp_lock_block_allocate();
         }
+        ANNOTATE_IGNORE_WRITES_END();
 
         // Insert lock in the table so that it can be freed in __kmp_cleanup,
         // and debugger has info on all allocated locks.
diff -rupN libomp_oss_orig/src/kmp_runtime.c libomp_oss/src/kmp_runtime.c
--- libomp_oss_orig/src/kmp_runtime.c	2013-12-13 10:08:47.000000000 -0800
+++ libomp_oss/src/kmp_runtime.c	2014-09-23 10:38:44.000000000 -0700
@@ -68,6 +68,7 @@
 #include <process.h>
 #endif
 
+#include "dynamic_annotations.h"
 
 #if defined(KMP_GOMP_COMPAT)
 char const __kmp_version_alt_comp[] = KMP_VERSION_PREFIX "alternative compiler support: yes";
@@ -1204,6 +1205,7 @@ __kmp_linear_barrier_gather( enum barrie
         // the team is valid any more - it could be deallocated by the master
         // thread at any time.
         //
+        ANNOTATE_HAPPENS_BEFORE(this_thr);
         __kmp_release( other_threads[0], &thr_bar -> b_arrived, kmp_release_fence );
 
     } else {
@@ -1233,6 +1235,7 @@ __kmp_linear_barrier_gather( enum barrie
                               new_state, FALSE
                               USE_ITT_BUILD_ARG( itt_sync_obj )
                               );
+            ANNOTATE_HAPPENS_AFTER(other_threads[ i ]);
 
             if (reduce) {
 
@@ -1316,6 +1319,7 @@ __kmp_tree_barrier_gather( enum barrier_
             __kmp_wait_sleep( this_thr, &child_bar -> b_arrived, new_state, FALSE
                               USE_ITT_BUILD_ARG( itt_sync_obj)
                               );
+            ANNOTATE_HAPPENS_AFTER(child_thr);
 
             if (reduce) {
 
@@ -1353,6 +1357,7 @@ __kmp_tree_barrier_gather( enum barrier_
         // the team is valid any more - it could be deallocated by the master
         // thread at any time.
         //
+        ANNOTATE_HAPPENS_BEFORE(this_thr);
         __kmp_release( other_threads[parent_tid], &thr_bar -> b_arrived, kmp_release_fence );
 
     } else {
@@ -1435,6 +1440,7 @@ __kmp_hyper_barrier_gather( enum barrier
             // team is valid any more - it could be deallocated by the master
             // thread at any time.
             //
+            ANNOTATE_HAPPENS_BEFORE(this_thr);
             __kmp_release( other_threads[parent_tid], &thr_bar -> b_arrived, kmp_release_fence );
             break;
         }
@@ -1466,6 +1472,7 @@ __kmp_hyper_barrier_gather( enum barrier
             __kmp_wait_sleep( this_thr, &child_bar -> b_arrived, new_state, FALSE
                               USE_ITT_BUILD_ARG (itt_sync_obj)
                               );
+            ANNOTATE_HAPPENS_AFTER(child_thr);
 
 #if USE_ITT_BUILD
             // Barrier imbalance - write min of the thread time and a child time to the thread.
@@ -1559,6 +1566,7 @@ __kmp_linear_barrier_release( enum barri
                                 other_threads[i]->th.th_bar[bt].bb.b_go + KMP_BARRIER_STATE_BUMP
                                 ) );
 
+                ANNOTATE_HAPPENS_BEFORE(other_threads[ i ]);
                 __kmp_release( other_threads[ i ],
                                &other_threads[ i ]-> th.th_bar[ bt ].bb.b_go, kmp_acquire_fence );
             }
@@ -1572,6 +1580,7 @@ __kmp_linear_barrier_release( enum barri
         __kmp_wait_sleep( this_thr, &thr_bar -> b_go, KMP_BARRIER_STATE_BUMP, TRUE
                           USE_ITT_BUILD_ARG(itt_sync_obj)
                           );
+        ANNOTATE_HAPPENS_AFTER(this_thr);
 
 #if USE_ITT_BUILD && OMP_30_ENABLED && USE_ITT_NOTIFY
         if ( ( __itt_sync_create_ptr && itt_sync_obj == NULL ) || KMP_ITT_DEBUG ) {
@@ -1657,6 +1666,7 @@ __kmp_tree_barrier_release( enum barrier
         __kmp_wait_sleep( this_thr, &thr_bar -> b_go, KMP_BARRIER_STATE_BUMP, TRUE
                           USE_ITT_BUILD_ARG(itt_sync_obj)
                           );
+        ANNOTATE_HAPPENS_AFTER(this_thr);
 
 #if USE_ITT_BUILD && OMP_30_ENABLED && USE_ITT_NOTIFY
         if ( ( __itt_sync_create_ptr && itt_sync_obj == NULL ) || KMP_ITT_DEBUG ) {
@@ -1744,6 +1754,7 @@ __kmp_tree_barrier_release( enum barrier
                             child_bar -> b_go + KMP_BARRIER_STATE_BUMP ) );
 
             /* release child from barrier */
+            ANNOTATE_HAPPENS_BEFORE(child_thr);
             __kmp_release( child_thr, &child_bar -> b_go, kmp_acquire_fence );
 
             child++;
@@ -1793,6 +1804,7 @@ __kmp_hyper_barrier_release( enum barrie
         __kmp_wait_sleep( this_thr, &thr_bar -> b_go, KMP_BARRIER_STATE_BUMP, TRUE
                           USE_ITT_BUILD_ARG( itt_sync_obj )
                           );
+        ANNOTATE_HAPPENS_AFTER(this_thr);
 
 #if USE_ITT_BUILD && OMP_30_ENABLED && USE_ITT_NOTIFY
         if ( ( __itt_sync_create_ptr && itt_sync_obj == NULL ) || KMP_ITT_DEBUG ) {
@@ -1919,6 +1931,7 @@ __kmp_hyper_barrier_release( enum barrie
                                 child_bar -> b_go + KMP_BARRIER_STATE_BUMP ) );
 
                 /* release child from barrier */
+                ANNOTATE_HAPPENS_BEFORE(child_thr);
                 __kmp_release( child_thr, &child_bar -> b_go, kmp_acquire_fence );
             }
         }
@@ -6724,6 +6737,7 @@ __kmp_reap_thread(
             /* Assume the threads are at the fork barrier here */
             KA_TRACE( 20, ("__kmp_reap_thread: releasing T#%d from fork barrier for reap\n", gtid ) );
             /* Need release fence here to prevent seg faults for tree forkjoin barrier (GEH) */
+            ANNOTATE_HAPPENS_BEFORE(thread);
             __kmp_release(
                 thread,
                 &thread->th.th_bar[ bs_forkjoin_barrier ].bb.b_go,
diff -rupN libomp_oss_orig/src/kmp_tasking.c libomp_oss/src/kmp_tasking.c
--- libomp_oss_orig/src/kmp_tasking.c	2013-12-13 10:08:48.000000000 -0800
+++ libomp_oss/src/kmp_tasking.c	2014-09-23 10:38:44.000000000 -0700
@@ -38,6 +38,7 @@
 #include "kmp_i18n.h"
 #include "kmp_itt.h"
 
+#include "dynamic_annotations.h"
 
 #if OMP_30_ENABLED
 
@@ -538,6 +539,7 @@ __kmp_free_task( kmp_int32 gtid, kmp_tas
     KMP_DEBUG_ASSERT( TCR_4(taskdata->td_incomplete_child_tasks) == 0 );
 
     taskdata->td_flags.freed = 1;
+    ANNOTATE_HAPPENS_BEFORE(taskdata);
     // deallocate the taskdata and shared variable blocks associated with this task
     #if USE_FAST_MEMORY
         __kmp_fast_free( thread, taskdata );
@@ -860,7 +862,8 @@ __kmp_task_alloc( ident_t *loc_ref, kmp_
     #else /* ! USE_FAST_MEMORY */
     taskdata = (kmp_taskdata_t *) __kmp_thread_malloc( thread, shareds_offset + sizeof_shareds );
     #endif /* USE_FAST_MEMORY */
-
+    ANNOTATE_HAPPENS_AFTER(taskdata);
+    
     task                      = KMP_TASKDATA_TO_TASK(taskdata);
 
     // Make sure task & taskdata are aligned appropriately
@@ -944,6 +947,7 @@ __kmp_task_alloc( ident_t *loc_ref, kmp_
     KA_TRACE(20, ("__kmp_task_alloc(exit): T#%d created task %p parent=%p\n",
                   gtid, taskdata, taskdata->td_parent) );
 
+    ANNOTATE_HAPPENS_BEFORE(task);
     return task;
 }
 
@@ -989,6 +993,7 @@ __kmp_invoke_task( kmp_int32 gtid, kmp_t
     KA_TRACE(30, ("__kmp_invoke_task(enter): T#%d invoking task %p, current_task=%p\n",
                   gtid, taskdata, current_task) );
 
+    ANNOTATE_HAPPENS_AFTER(task);
     __kmp_task_start( gtid, task, current_task );
 
 #if OMP_40_ENABLED
@@ -1024,6 +1029,7 @@ __kmp_invoke_task( kmp_int32 gtid, kmp_t
     }
 #endif // OMP_40_ENABLED
 
+    ANNOTATE_HAPPENS_BEFORE(taskdata->td_parent);
     __kmp_task_finish( gtid, task, current_task );
 
     KA_TRACE(30, ("__kmp_inovke_task(exit): T#%d completed task %p, resuming task %p\n",
@@ -1063,6 +1069,7 @@ __kmpc_omp_task_parts( ident_t *loc_ref,
                   "loc=%p task=%p, return: TASK_CURRENT_NOT_QUEUED\n", gtid, loc_ref,
                   new_taskdata ) );
 
+    ANNOTATE_HAPPENS_BEFORE(new_task);
     return TASK_CURRENT_NOT_QUEUED;
 }
 
@@ -1099,6 +1106,7 @@ __kmpc_omp_task( ident_t *loc_ref, kmp_i
     KA_TRACE(10, ("__kmpc_omp_task(exit): T#%d returning TASK_CURRENT_NOT_QUEUED: loc=%p task=%p\n",
                   gtid, loc_ref, new_taskdata ) );
 
+    ANNOTATE_HAPPENS_BEFORE(new_task);
     return TASK_CURRENT_NOT_QUEUED;
 }
 
@@ -1155,6 +1163,7 @@ __kmpc_omp_taskwait( ident_t *loc_ref, k
     KA_TRACE(10, ("__kmpc_omp_taskwait(exit): T#%d task %p finished waiting, "
                   "returning TASK_CURRENT_NOT_QUEUED\n", gtid, taskdata) );
 
+    ANNOTATE_HAPPENS_AFTER(taskdata);
     return TASK_CURRENT_NOT_QUEUED;
 }
 
@@ -1275,6 +1284,7 @@ __kmpc_end_taskgroup( ident_t* loc, int 
     __kmp_thread_free( thread, taskgroup );
 
     KA_TRACE(10, ("__kmpc_end_taskgroup(exit): T#%d task %p finished waiting\n", gtid, taskdata) );
+    ANNOTATE_HAPPENS_AFTER(taskdata);
 }
 #endif
 
@@ -1993,8 +2003,10 @@ __kmp_realloc_task_threads_data( kmp_inf
                 // Make the initial allocate for threads_data array, and zero entries
                 // Cannot use __kmp_thread_calloc() because threads not around for
                 // kmp_reap_task_team( ).
+                ANNOTATE_IGNORE_WRITES_BEGIN();
                 *threads_data_p = (kmp_thread_data_t *)
                                   __kmp_allocate( nthreads * sizeof(kmp_thread_data_t) );
+                ANNOTATE_IGNORE_WRITES_END();
 #ifdef BUILD_TIED_TASK_STACK
                 // GEH: Figure out if this is the right thing to do
                 for (i = 0; i < nthreads; i++) {
diff -rupN libomp_oss_orig/src/makefile.mk libomp_oss/src/makefile.mk
--- libomp_oss_orig/src/makefile.mk	2013-12-13 10:08:48.000000000 -0800
+++ libomp_oss/src/makefile.mk	2014-09-23 10:38:44.000000000 -0700
@@ -116,6 +116,7 @@ define curr_config
     CXXFLAGS=$(subst $(space),_,$(CXXFLAGS))
     FFLAGS=$(subst $(space),_,$(FFLAGS))
     LDFLAGS=$(subst $(space),_,$(LDFLAGS))
+    TSAN=$(tsan)
 endef
 # And check it.
 include $(tools_dir)src/common-checks.mk
@@ -656,6 +657,9 @@ ld-flags   += $(LDFLAGS)
 # --------------------------------------------------------------------------------------------------
 # Files.
 # --------------------------------------------------------------------------------------------------
+ifeq "$(tsan)" "enabled"
+  cpp-flags += -D DYNAMIC_ANNOTATIONS_ENABLED=1
+endif
 
 # Library files. These files participate in all kinds of library.
 lib_c_items :=      \
@@ -782,6 +786,9 @@ else
             _lib_item += mt
         endif
     endif
+    ifeq "$(tsan)" "enabled"
+	_lib_item += _tsan
+    endif
 endif
 # _lib_item is a list of space separated name parts. Remove spaces to form final name.
 lib_item = $(subst $(space),,$(_lib_item))
@@ -1264,9 +1271,12 @@ ifneq "$(os)" "lrb"
         # On Linux* OS and OS X* the test is good enough because GNU compiler knows nothing
         # about libirc and Intel compiler private lib directories, but we will grep verbose linker
         # output just in case.
-        tt-c        = gcc
+        tt-c        = $(c)
         ifeq "$(os)" "lin"    # GCC on OS X* does not recognize -pthread.
-            tt-c-flags  += -pthread
+            tt-c-flags  += -pthread 
+            ifeq "$(tsan)" "enabled"
+                tt-c-flags  += -fsanitize=thread
+            endif
         endif
         tt-c-flags += -o $(tt-exe-file)
         ifneq "$(filter 32 32e 64,$(arch))" ""
diff -rupN libomp_oss_orig/src/z_Linux_util.c libomp_oss/src/z_Linux_util.c
--- libomp_oss_orig/src/z_Linux_util.c	2013-12-13 10:08:48.000000000 -0800
+++ libomp_oss/src/z_Linux_util.c	2014-09-23 10:38:44.000000000 -0700
@@ -49,6 +49,8 @@
 #include <sys/resource.h>
 #include <sys/syscall.h>
 
+#include "dynamic_annotations.h"
+
 #if KMP_OS_LINUX
 # include <sys/sysinfo.h>
 # if KMP_OS_LINUX && (KMP_ARCH_X86 || KMP_ARCH_X86_64 || KMP_ARCH_ARM)
@@ -1257,13 +1259,13 @@ __kmp_reap_monitor( kmp_info_t *th )
        but if the monitor dies after the pthread_kill call and before the pthread_join
        call, it will still hang. */
 
-    status = pthread_kill( th->th.th_info.ds.ds_thread, 0 );
+/*    status = pthread_kill( th->th.th_info.ds.ds_thread, 0 );
     if (status == ESRCH) {
 
         KA_TRACE( 10, ("__kmp_reap_monitor: monitor does not exist, returning\n") );
 
     } else
-    {
+    {*/
         status = pthread_join( th->th.th_info.ds.ds_thread, & exit_val);
         if (exit_val != th) {
             __kmp_msg(
@@ -1273,7 +1275,7 @@ __kmp_reap_monitor( kmp_info_t *th )
                 __kmp_msg_null
             );
         }
-    }
+//    }
 
     th->th.th_info.ds.ds_tid  = KMP_GTID_DNE;
     th->th.th_info.ds.ds_gtid = KMP_GTID_DNE;
@@ -1294,18 +1296,17 @@ __kmp_reap_worker( kmp_info_t *th )
     KMP_MB();       /* Flush all pending memory write invalidates.  */
 
     KA_TRACE( 10, ("__kmp_reap_worker: try to reap T#%d\n", th->th.th_info.ds.ds_gtid ) );
-
     /* First, check to see whether the worker thread exists.  This could prevent a hang,
        but if the worker dies after the pthread_kill call and before the pthread_join
        call, it will still hang. */
 
         {
-            status = pthread_kill( th->th.th_info.ds.ds_thread, 0 );
+/*            status = pthread_kill( th->th.th_info.ds.ds_thread, 0 );
             if (status == ESRCH) {
                 KA_TRACE( 10, ("__kmp_reap_worker: worker T#%d does not exist, returning\n",
                                th->th.th_info.ds.ds_gtid ) );
             }
-            else {
+            else {*/
                 KA_TRACE( 10, ("__kmp_reap_worker: try to join with worker T#%d\n",
                                th->th.th_info.ds.ds_gtid ) );
 
@@ -1326,7 +1327,7 @@ __kmp_reap_worker( kmp_info_t *th )
                                     th->th.th_info.ds.ds_gtid, exit_val ) );
                 }
 #endif /* KMP_DEBUG */
-            }
+//            }
         }
 
     KA_TRACE( 10, ("__kmp_reap_worker: done reaping T#%d\n", th->th.th_info.ds.ds_gtid ) );
@@ -1607,6 +1608,7 @@ __kmp_suspend_initialize( void )
 static void
 __kmp_suspend_initialize_thread( kmp_info_t *th )
 {
+    ANNOTATE_HAPPENS_AFTER(&th->th.th_suspend_init_count);
     if ( th->th.th_suspend_init_count <= __kmp_fork_count ) {
         /* this means we haven't initialized the suspension pthread objects for this thread
            in this instance of the process */
@@ -1616,6 +1618,7 @@ __kmp_suspend_initialize_thread( kmp_inf
         status = pthread_mutex_init( &th->th.th_suspend_mx.m_mutex, & __kmp_suspend_mutex_attr );
         KMP_CHECK_SYSFAIL( "pthread_mutex_init", status );
         *(volatile int*)&th->th.th_suspend_init_count = __kmp_fork_count + 1;
+    ANNOTATE_HAPPENS_BEFORE(&th->th.th_suspend_init_count);
     };
 }
 
diff -rupN libomp_oss_orig/tools/build.pl libomp_oss/tools/build.pl
--- libomp_oss_orig/tools/build.pl	2013-12-13 10:08:50.000000000 -0800
+++ libomp_oss/tools/build.pl	2014-09-23 10:38:45.000000000 -0700
@@ -88,12 +88,13 @@ my $opts = {
     "mic-arch"        => { targets => "rtl",               base => 0, parms => { knf     => "*", knc       => "", knl => ""   }, suffix => sub { $_[ 0 ];                       } },
     "mic-os"          => { targets => "rtl",               base => 0, parms => { bsd     => "*", lin       => ""              }, suffix => sub { $_[ 0 ];                       } },
     "mic-comp"        => { targets => "rtl",               base => 0, parms => { native  => "*", offload   => ""              }, suffix => sub { substr( $_[ 0 ], 0, 3 );       } },
+    "tsan"    => { targets => "rtl",         base => 0, parms => { enabled => "*", disabled => ""               }, suffix => sub { "" } },
 };
 my $synonyms = {
     "debug" => [ qw{ dbg debg } ],
 };
 # This array specifies order of options to process, so it cannot be initialized with keys( %$opts ).
-my @all_opts   = qw{ target version lib-type link-type target-compiler mode omp-version coverage tcheck mic-arch mic-os mic-comp };
+my @all_opts   = qw{ target version lib-type link-type target-compiler mode omp-version coverage tcheck mic-arch mic-os mic-comp tsan};
 # This is the list of base options.
 my @base_opts  = grep( $opts->{ $_ }->{ base } == 1, @all_opts );
 # This is the list of extra options.
@@ -297,6 +298,7 @@ sub enqueue_jobs($$@) {
                     "VERSION=" . $set->{ version },
                     "TARGET_COMPILER=" . $set->{ "target-compiler" },
                     "suffix=" . $suf,
+                     "tsan=" . $set->{ "tsan" },
                     @goals,
                 ],
                 build_dir  => $build_dir
diff -rupN libomp_oss_orig/tools/check-tools.pl libomp_oss/tools/check-tools.pl
--- libomp_oss_orig/tools/check-tools.pl	2013-12-13 10:08:50.000000000 -0800
+++ libomp_oss/tools/check-tools.pl	2014-09-23 10:38:45.000000000 -0700
@@ -321,7 +321,7 @@ sub get_clang_compiler_version($) {
             ( $ver, $bld ) = ( $1, $2 );
         } else {
             if ( 0 ) {
-            } elsif ( $stdout =~ m{^.*? (\d+\.\d+) \((.*)\)}m ) {
+            } elsif ( $stdout =~ m{^.*? (\d+\.\d+(\.\d+)?) \((.*)\)}m ) {
                 # clang version 3.3 (tags/RELEASE_33/final)
                 ( $ver, $bld ) = ( $1, $2 );
             } 
